{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Jupyter notebook tutorial:\n",
    "#    Fitting models to data with *kafe2*\n",
    "\n",
    "                                                Johannes Gäßler, March 2021\n",
    "                                                Günter Quast, April 2020\n",
    "                                                Cedric Verstege, August 2020\n",
    "---\n",
    "## Jupyter Notebook Fundamentals\n",
    "\n",
    "This file of type `.ipynb` contains a tutorial as a `Jupyter notebook`.\n",
    "`Jupyter` provides a browser interface with a (simple) development environment for *Python* code\n",
    "and explanatory texts in intuitive *Markdown* format.\n",
    "The input of formulas in *LaTeX* format is also supported.\n",
    "\n",
    "A summary of the most important commands for using *Jupyter* as a working environment can be\n",
    "found in the notebook\n",
    "[*JupyterCheatsheet.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/JupyterCheatsheet.ipynb)\n",
    "(German).\n",
    "Basics for statistical data analysis can be found in the notebooks\n",
    "[*IntroStatistik.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/IntroStatistik.ipynb)\n",
    "(German) and\n",
    "[*Fehlerrechnung.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/Fehlerrechnung.ipynb) (German).\n",
    "\n",
    "In *Jupyter*, code and text are entered into individual cells.\n",
    "Active cells are indicated by a blue bar in the margin.\n",
    "They can be in two states: in edit mode the input field is white, in command mode it is grayed out.\n",
    "Clicking in the border area selects the command mode, clicking in the text field of a code cell\n",
    "switches to edit mode.\n",
    "The `esc` key can also be used to leave the edit mode.\n",
    "\n",
    "Pressing `a` in command mode creates a new empty cell above the active cell, `b` creates one below.\n",
    "Entering `dd` deletes the corresponding cell.\n",
    "\n",
    "Cells can be either of the type `Markdown` or `Code`.\n",
    "Entering `m` in command mode sets the type Markdown, entering `y` selects the type Code.\n",
    "\n",
    "The cell content is processed - i.e. setting text or executing code - by entering `shift+return`,\n",
    "or `alt+return` if a new, empty cell should also be created.\n",
    "\n",
    "The settings mentioned here as well as the insertion, deletion or execution of cells can also be\n",
    "executed via the pull-down menu at the top.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: *kafe*2\n",
    "***\n",
    "\n",
    "\n",
    "*kafe2* is an extended version of the *kafe* package developed since 2012 for the fitting of model\n",
    "functions to data.\n",
    "\n",
    "It supports different data types like simple indexed data,\n",
    "two-dimensional data points (one quantity *x* and one dependent quantity *y*),\n",
    "or one-dimensional data that can be binned as a histogram.\n",
    "Uncertainties of both dependent and independent quantities and, if applicable,\n",
    "their correlations are supported.\n",
    "For this purpose, the global covariance matrix is created from different types\n",
    "of specified uncertainties and taken into account in the fitting.\n",
    "Compared to many other fitting tools, this possibility is a unique feature of *kafe(2)*.\n",
    "\n",
    "Simultaneous fitting of several models is also supported.\n",
    "Each with its own and additionally all or several common parameters\n",
    "to different data sets (\"multi fit\").\n",
    "\n",
    "To minimize the distance between data and model function(s) numerical methods are applied,\n",
    "which are derived from the open source,\n",
    "*Python*-based software environment *SciPy* or the *MINUIT* package developed at CERN.\n",
    "The respective minimized distance metric (or the \"cost function\") is equal to the negative\n",
    "natural logarithm of the likelihood function for the data and the given model multiplied by a\n",
    "factor of two ($-2\\,\\ln{\\cal L}$).\n",
    "For Gaussian uncertainties of the data points, this corresponds to the method\n",
    "of least squares (also called \"$\\chi^2$ method\").\n",
    "Other cost functions based on the method of maximum likelihood are also available for the fitting of probability densities to histograms or indexed data.\n",
    "\n",
    "To determine the confidence intervals of idividual model parameters as well as\n",
    "two-dimensional confidence contours for pairs of parameters *kafe2* makes use of the\n",
    "profile likelihood method.\n",
    "\n",
    "*kafe2* contains a stand-alone application *kafe2go*, which allows fittings without the creation of own code;\n",
    "data, model function and options are specified in a *YAML* configuration file.\n",
    "A fit can then be performed from the command line by calling:\n",
    "\n",
    "`kafe2go <name>.yaml`\n",
    "\n",
    "Alternatively *kafe2* can be used as part of a *Python* program.\n",
    "This tutorial provides insight into how to do this.\n",
    "In general the procedure is as follows:\n",
    "\n",
    "  - Definition and initialization of a data container for the respective fitting (classes\n",
    "    *IndexedContainer*, *XYContainer*, *HistContainer*, *UnbinnedContainer*).\n",
    "  - Creation of a suitable object to perform the fitting that connects the data container to a model\n",
    "    (the general class *Fit* or specialized classes *IndexedFit*, *XYFit*, *HistFit*, *UnbinnedFit*).\n",
    "  - Implementation of the fitting by means of `<Fit_Object>.do_fit()` and printing the results to the\n",
    "    console using `<Fit_Object>.report()` or by directly accessing the results of the fit\n",
    "    object.\n",
    "  - If necessary, generation and display of a graphic that shows the fit results with the generic class *Plot*.\n",
    "\n",
    "**The following examples show the actual procedure.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General settings and useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function  # python2-compatibility\n",
    "import sys, os\n",
    "\n",
    "# Lines with % or %% at the beginning are so-called \"magic commands\",\n",
    "# that specify the cell type or options for displaying graphics.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Presets for *kafe2*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kafe2 import config, XYContainer, Fit, Plot\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# set better default figure size for kafe2\n",
    "# plt.rcParams['figure.figsize']=[12., 5.]\n",
    "#        !!!  must be done after importing kafe2 (will else be overwritten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Simple example for fitting with `kafe2`\n",
    "***\n",
    "\n",
    "The following code illustrates the fitting of functions with the *kafe2* fitting tool:\n",
    "\n",
    "```\n",
    "# Create an XYContainer object to hold the xy data for the fit:\n",
    "xy_data = XYContainer(x_data=[1.0, 2.0, 3.0, 4.0],\n",
    "                      y_data=[2.3, 4.2, 7.5, 9.4])\n",
    "# x_data and y_data are combined depending on their order.\n",
    "# The above translates to the points (1.0, 2.3), (2.0, 4.2),\n",
    "#     (3.0, 7.5), and (4.0, 9.4).\n",
    "\n",
    "# Important: Specify uncertainties for the data:\n",
    "xy_data.add_error(axis='x', err_val=0.1)\n",
    "xy_data.add_error(axis='y', err_val=0.4)\n",
    "\n",
    "# Create an XYFit object from the xy data container.\n",
    "# By default, a linear function f=a*x+b will be used as the model function.\n",
    "line_fit = Fit(data=xy_data)\n",
    "\n",
    "# Perform the fit: Find values for a and b that minimize the\n",
    "#     difference between the model function and the data.\n",
    "line_fit.do_fit()  # This will throw a warning if no errors were specified.\n",
    "\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "line_fit.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "plot = Plot(fit_objects=line_fit)  # Create a kafe2 plot object.\n",
    "plot.plot()  # Do the plot.\n",
    "\n",
    "# Show the fit result.\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Paste the code into the empty cell below and execute it by pressing `shift+return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# simple example: straight line adjustment with kafe2\n",
    "# -> insert code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Correlated uncertainties\n",
    "***\n",
    "\n",
    "To illustrate the possibilities for dealing with uncertainties, we add a further correlated\n",
    "uncertainty of the dependent quantities *y*:\n",
    "```\n",
    "xy_data.add_error(axis='y', err_val=0.3, correlation=1.)\n",
    "```\n",
    "\n",
    "Insert this line in the above code.\n",
    "You can make the output a bit clearer by omitting the output of the data and the model.\n",
    "To do this, modify the parameters of the `report()` method:\n",
    "```\n",
    "line_fit.report(show_data=False, show_model=False)\n",
    "```\n",
    "Now repeat the fit.\n",
    "\n",
    "As expected, such an uncertainty common to all data points does not affect the gradient of the\n",
    "straight line, but only the parameter *b*, whose uncertainty now becomes greater - corresponding\n",
    "to the square root of the sum of the squared uncertainties of +/-0.58 from the original fit and the\n",
    "additional correlated uncertainty of +/-0.40.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copy and extend code from the previous example\n",
    "# ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Comparison of Two Different Models\n",
    "***\n",
    "\n",
    "Simple models with linear parameters are not sufficient in practice.\n",
    "The following example shows the fitting of a linear and an exponential model to the same data.\n",
    "\n",
    "To define a model function for kafe2 simply write it as a Python function.\n",
    "Important: The first argument of the model function is interpreted as the\n",
    "independent variable of the fit. It is not being during the fit and it's the\n",
    "quantity represented by the x axis of the fit.\n",
    "\n",
    "\n",
    "Definition of two model functions:\n",
    "```\n",
    "# Our first model is a simple linear function:\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "\n",
    "# Our second model is a simple exponential function.\n",
    "# The kwargs in the function header specify parameter defaults.\n",
    "def exponential_model(x, A0=1., x0=5.):\n",
    "    return A0 * np.exp(x/x0)\n",
    "```\n",
    "\n",
    "Definition of the data as a *kafe2* `XYContainer`:\n",
    "```\n",
    "# The data for this exercise:\n",
    "x = [19.8, 3.0, 5.1, 16.1, 8.2, 11.7, 6.2, 10.1]\n",
    "y = [23.2, 3.2, 4.5, 19.9, 7.1, 12.5, 4.5, 7.2]\n",
    "data2 = XYContainer(x_data=x, y_data=y)\n",
    "data2.add_error(axis='x', err_val=0.3)\n",
    "data2.add_error(axis='y', err_val=0.15, relative=True)\n",
    "```\n",
    "\n",
    "Set labels for the axes and data so that they can be clearly identified in the\n",
    "graphical output later on:\n",
    "```\n",
    "data2.label = 'my data points'\n",
    "data2.axis_labels=['my x values', 'my y values']\n",
    "```\n",
    "\n",
    "Create two fit objects with the same data but different model functions:\n",
    "```\n",
    "# Create 2 Fit objects with the same data but with different model functions:\n",
    "linear_fit = Fit(data2, model_function=linear_model)\n",
    "exponential_fit = Fit(data2, model_function=exponential_model)\n",
    "```\n",
    "\n",
    "In order to make the plot look better, we define LaTeX expressions for the functions,\n",
    "the names of the parameters, and the legend in the graphical output:\n",
    "```\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit.assign_parameter_latex_names(a='a', b='b')\n",
    "linear_fit.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "linear_fit.model_label = 'my linear model'\n",
    "exponential_fit.assign_parameter_latex_names(A0='A_0', x0='x_0')\n",
    "exponential_fit.assign_model_function_latex_expression(\"{A0} e^{{{x}/{x0}}}\")\n",
    "exponential_fit.model_label = 'my exponential model'\n",
    "```\n",
    "\n",
    "Finally the code to perform the fits:\n",
    "```\n",
    "# Perform the fits:\n",
    "linear_fit.do_fit()\n",
    "exponential_fit.do_fit()\n",
    "\n",
    "# Optional: Print out a report on the result of each fit.\n",
    "linear_fit.report()\n",
    "exponential_fit.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p = Plot(fit_objects=[linear_fit, exponential_fit], separate_figures=False)\n",
    "p.plot(fit_info=True)\n",
    "\n",
    "# Show the fit results:\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Paste the code into the empty cell below and execute it by pressing 'shift+return'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison of two models with kafe2\n",
    "# -> insert code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hypothesis Test to Assess the Models\n",
    "***\n",
    "\n",
    "The graphical output does not clearly indicate which of the models is acceptable.\n",
    "For this purpose a hypothesis test can be performed which indicates the so-called $\\chi^2$\n",
    "probability - i.e. the probability of obtaining a worse value for $\\chi^2$ at the\n",
    "minimum than the observed one.\n",
    "A higher value corresponds to a better fit.\n",
    "\n",
    "It is calculated from the cumulative distribution density of the Chi2 function:\n",
    "```\n",
    "from scipy import stats\n",
    "\n",
    "def chi2prob(chi2, ndf):\n",
    "  \"\"\" chi2-probability\n",
    "\n",
    "    Args:\n",
    "      * chi2: chi2 value\n",
    "      * ndf: number of degrees of freedom\n",
    "\n",
    "    Returns:\n",
    "      * float: chi2 probability\n",
    "  \"\"\"\n",
    "\n",
    "  return 1.- stats.chi2.cdf(chi2, ndf)\n",
    "```\n",
    "\n",
    "Enter the code for the $\\chi^2$ probability in the blank line below and check the\n",
    "two results you got above.\n",
    "\n",
    "**Hint**: you can either copy the values for $\\chi^2$ and the number of degrees of freedom\n",
    "from the output of the previous cell or you can access them via the properties\n",
    "`goodness_of_fit` and `ndf` of the fits.\n",
    "The property `cost_function_value` is not suitable because it is the sum of $\\chi^2$ and\n",
    "correctional terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the quality of the fits\n",
    "# -> enter code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using *kafe2* outside this notebook the $\\chi^2$ probability should be calculated via\n",
    "the corresponding property of fit objects.\n",
    "For example, for the above fits this could be achieved via\n",
    "`chi2_prob = linear_fit.chi2_probability`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Examination of the Non-Linear Model\n",
    "***\n",
    "\n",
    "For model functions that are non-linear in their parameters, the $\\chi^2$ distribution around \n",
    "the minimum is only approximately a parabola - sometimes the deviation is quite large.\n",
    "Whether the deviation is negligible can be checked by using the profile likelihood and\n",
    "displaying confidence contours.\n",
    "```\n",
    "from kafe2 import ContoursProfiler\n",
    "\n",
    "# Create contour plot and profiles for the exponential fit\n",
    "cpf = ContoursProfiler(exponential_fit)\n",
    "cpf.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "plt.show()\n",
    "```\n",
    "Enter the code example in the line below to check the fit of the exponential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the nonlinear fits\n",
    "# -> enter code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Asymmetric parameter uncertainties\n",
    "***\n",
    "\n",
    "If the deviations are large, asymmetric uncertainties must be specified.\n",
    "For this purpose, the option *asymmetric_parameter_errors=True* is set in the *report* function\n",
    "of the fit class.\n",
    "```\n",
    "exponential_fit.report(asymmetric_parameter_errors=True)\n",
    "```\n",
    "It is recommended to document the contours in such cases with strongly asymmetrical parameter\n",
    "uncertainties if more than one parameter is of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# enter code here for output of asymmetric parameters\n",
    "# ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: You can show asymmetric parameter errors in plots via \n",
    "`Plot.plot(asymmetric_parameter_errors=True)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Influencing the Graphical Output\n",
    "***\n",
    "\n",
    "The graphical output was suboptimal in some regards.\n",
    "For example, two data sets were shown in the legend although both models used the exact same data.\n",
    "In addition, marker properties and colors can be customized.\n",
    "\n",
    "To influence the graphic *kafe2* provides a method `Plot.customize()` which can be used\n",
    "to specify values for *matplotlib* parameters for different graphic elements\n",
    "(*plot_types*: 'data', 'model_line', 'model_error_band', 'ratio', 'ratio_error_band').\n",
    "\n",
    "The parameters relevant for a *plot_type* and their current values\n",
    "can be displayed using a function of the *Plot* class:\n",
    "```\n",
    "p.get_keywords('model_error_band')\n",
    "```\n",
    "\n",
    "The names used for objects and possible values correspond to the names in the configuration file\n",
    "*matplotlibrc* for *matplotlib*.\n",
    "\n",
    "To change the name for the data set and suppress the second output, use the following call:\n",
    "```\n",
    "p.customize('data', 'label', [\"test data\", None])\n",
    "```\n",
    "The first argument specifies the subplot for which to set keywords.\n",
    "The second argument specifies which keyword to set.\n",
    "The third argument is a list of values to set for the keyword for each fit\n",
    "managed by the plot object.\n",
    "\n",
    "Alternatively the third argument can be a list of tuples consisting of fit indices\n",
    "and values.\n",
    "```\n",
    "p.customize('data', 'label', [(0, \"test data\"), (1, None)])\n",
    "```\n",
    "This syntax makes it possible to set keywords for only a part of the fits managed by the\n",
    "plot object.\n",
    "\n",
    "Marker type, size and color of the marker and error bars can also be customized:\n",
    "```\n",
    "# data\n",
    "p.customize('data', 'marker', ['o', 'o'])\n",
    "p.customize('data', 'markersize', [5, 5])\n",
    "p.customize('data', 'color', [(0, 'blue'), (1,'blue')]) # note: although 2nd label is suppressed\n",
    "p.customize('data', 'ecolor', [(0, 'blue'), (1, 'blue')]) # note: although 2nd label is suppressed\n",
    "```\n",
    "\n",
    "The corresponding values for the model function can also be customized:\n",
    "```\n",
    "# model\n",
    "p.customize('model_line', 'color', ['orange', 'lightgreen'])\n",
    "p.customize('model_error_band', 'label', [(0, r'$\\pm 1 \\sigma$'), (1, r'$\\pm 1 \\sigma$')])\n",
    "p.customize('model_error_band', 'color', [(0, 'orange')])\n",
    "p.customize('model_error_band', 'color', [(1, 'lightgreen')])\n",
    "```\n",
    "\n",
    "It is also possible to change parameters using *matplotlib* functions.\n",
    "To change the size of the axis labels, use the following calls:\n",
    "```\n",
    "# Größe der Achsenbeschriftungen\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=20, titlesize=25)\n",
    "```\n",
    "Note: the above call sets the *matplotlib* parameters globally.\n",
    "Plots unrelated to *kafe2* are also being influenced.\n",
    "\n",
    "Of course, after these changes the output graphic must be recreated and displayed:\n",
    "```\n",
    "p.plot()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code to test here:\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Output of fit results as variables\n",
    "***\n",
    "\n",
    "In many applications it is necessary to continue to use the output of a fit in the program code.\n",
    "This can be done with the *kafe2* function *Fit.get_result_dict()*, which returns a\n",
    "*Python* dictionary with the fit results.\n",
    "\n",
    "For example:\n",
    "```\n",
    "result_0 = <Fit_object>.get_result_dict()\n",
    "```\n",
    "A formatted output can be obtained with the following line:\n",
    "```\n",
    "print(\"\\n\".join(\"{}\\t{}\".format(k, v) for k, v in result_0.items()))\n",
    "```\n",
    "The values contained in the dictionary can also be obtained via the corresponding properties\n",
    "of the fit object.\n",
    "Note: the names of some of the properties are slightly different, more details further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test output here\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Non-Linearity due to Uncertainties in *x* Direction\n",
    "***\n",
    "\n",
    "If the errors in *x* direction are increased, fitting a straight line also becomes a\n",
    "non-linear problem.\n",
    "To illustrate this, we repeat the same fit as above with increased uncertainties on\n",
    "the x values:\n",
    "```\n",
    "# The data for this exercise:\n",
    "data3 = XYContainer(x_data=x, y_data=y)\n",
    "data3.add_error(axis='x', err_val=1.0) # Was 0.3 before.\n",
    "data3.add_error(axis='y', err_val=0.15, relative=True)\n",
    "\n",
    "# Create 2 Fit objects with the same data but with different model functions:\n",
    "linear_fit2 = Fit(data3, model_function=linear_model)\n",
    "\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit2.assign_parameter_latex_names(x='x', a='a', b='b')\n",
    "linear_fit2.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "\n",
    "# Perform the fits:\n",
    "linear_fit2.do_fit()\n",
    "\n",
    "# Optional: Print out a report on the result of each fit.\n",
    "#linear_fit2.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p2 = Plot(fit_objects = linear_fit2)\n",
    "\n",
    "p2.plot(fit_info=True)\n",
    "\n",
    "# Create a contour plot and profiles for the linear fit:\n",
    "cpf2 = ContoursProfiler(linear_fit2)\n",
    "cpf2.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "\n",
    "# Show the fit results.\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter the above code here:\n",
    "# -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Adding a Square Model\n",
    "\n",
    "Try adding a square model, $y(x) = ax^2 + b x + c$, and plot it together with the\n",
    "linear and exponential model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.7 Relative uncertainties\n",
    "***\n",
    "\n",
    "We had already seen that *kafe2* allows the declaration of relative uncertainties\n",
    "which we want to examine more closely in this example.\n",
    "\n",
    "Adjustments with relative uncertainties suffer from the fact that the estimate of the parameter\n",
    "values is distorted.\n",
    "This is because measured values that fluctuate to smaller values have smaller uncertainties;\n",
    "the uncertainties are correspondingly greater when the measured values fluctuate upwards.\n",
    "If the random fluctuations were exactly the other way round, other uncertainties would be assigned.\n",
    "It would be correct to relate the relative uncertainties to the true values, which we do not know.\n",
    "Instead, the option ``reference='model'`` allows the uncertainties to be dependent on the model\n",
    "value - still not completely correct, but much better.\n",
    "\n",
    "The effect can be illustrated by repeating the example of linear regression from 2.1 but this time\n",
    "the relative uncertainties are related to the model values.\n",
    "Instead of using a method of the data container, the uncertainties are now added using the\n",
    "method ``add_error()`` of the fit object;\n",
    "the corresponding place in the code is marked with `-->`.\n",
    "In the code below, the original result from 2.1 is used and is also shown in the output graphic \n",
    "to illustrate the difference.\n",
    "Profile likelihood and contours are also displayed to demonstrate the non-linearity.\n",
    "\n",
    "```    \n",
    "data1_4 = XYContainer(x_data=x, y_data=y)\n",
    "data1_4.add_error(axis='x', err_val=0.3)\n",
    "data1_4.label = 'Data, rel. uncertainties on the model'\n",
    "\n",
    "# Create Fit:\n",
    "linear_fit4 = Fit(data1_4, model_function=linear_model)\n",
    "# --> relative uncertainties with reference to model specified here:\n",
    "linear_fit4.add_error(axis='y', err_val=0.15, relative=True, reference='model')\n",
    "\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit4.assign_parameter_latex_names(x='x', a='a', b='b')\n",
    "linear_fit4.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit4.assign_parameter_latex_names(a='a', b='b')\n",
    "linear_fit4.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "linear_fit4.model_label = 'linear m. rel. Unsicherheiten'\n",
    "\n",
    "# Perform the fit:\n",
    "linear_fit4.do_fit()\n",
    "\n",
    "# Optional: print report.\n",
    "#linear_fit4.report(asymmetric_parameter_errors=True)\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p4 = Plot([linear_fit, linear_fit4])\n",
    "# Assign colors to data ...\n",
    "p4.customize('data', 'marker', [(0, 'o'), (1,'o')])\n",
    "p4.customize('data', 'markersize', [(0, 5), (1, 5)])\n",
    "p4.customize('data', 'color', [(0, 'grey'), (1,'red')]) # note: although 2nd label is suppressed\n",
    "p4.customize('data', 'ecolor', [(0, 'grey'), (1, 'red')]) # note: although 2nd label is suppressed\n",
    "# ... and model.\n",
    "p4.customize('model_line', 'color', [(0, 'mistyrose'),(1, 'orange')])\n",
    "p4.customize('model_error_band', 'label', [(0, r'$\\pm 1 \\sigma$'),(1, r'$\\pm 1 \\sigma$')])\n",
    "p4.customize('model_error_band', 'color', [(0, 'mistyrose'),(1, 'orange')])\n",
    "\n",
    "p4.plot(asymmetric_parameter_errors=True)\n",
    "\n",
    "# Create contour plot and profiles for the linear fit:\n",
    "cpf4 = ContoursProfiler(linear_fit4)\n",
    "cpf4.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "\n",
    "# Show the fit results.\n",
    "plt.show()   \n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code here:\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Special Features of Complex (Non-Linear) Models\n",
    "---\n",
    "\n",
    "Another example of a non-linear fit is a damped oscillation of a thread pendulum.\n",
    "The corresponding measurement data are contained in the following code cell:\n",
    "```\n",
    "# the data\n",
    "t = [ ... ]\n",
    "t_errors = 0.05\n",
    "\n",
    "a = [ ... ]\n",
    "a_errors = 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the data:\n",
    "t = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0,\n",
    "     10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0, 14.5, 15.0, 15.5, 16.0, 16.5, 17.0, 17.5, 18.0, 18.5, 19.0,\n",
    "     19.5, 20.0, 20.5, 21.0, 21.5,22.0, 22.5, 23.0, 23.5, 24.0, 24.5, 25.0, 25.5, 26.0, 26.5, 27.0, 27.5, 28.0,\n",
    "     28.5, 29.0, 29.5, 30.0, 30.5, 31.0, 31.5, 32.0, 32.5, 33.0, 33.5, 34.0, 34.5, 35.0, 35.5, 36.0, 36.5, 37.0,\n",
    "     37.5, 38.0, 38.5, 39.0, 39.5, 40.0, 40.5, 41.0, 41.5, 42.0, 42.5, 43.0, 43.5, 44.0, 44.5, 45.0, 45.5, 46.0,\n",
    "     46.5, 47.0, 47.5, 48.0, 48.5, 49.0, 49.5, 50.0, 50.5, 51.0, 51.5, 52.0,52.5, 53.0, 53.5, 54.0, 54.5, 55.0,\n",
    "     55.5, 56.0, 56.5, 57.0, 57.5, 58.0, 58.5, 59.0, 59.5, 60.0]\n",
    "t_errors = 0.05\n",
    "\n",
    "a = [ 6.06,  5.17,  3.29,  0.64, -2.26, -4.56, -5.74, -5.58, -4.12, -1.62,\n",
    "      1.11,  3.56,  5.12,  5.43,  4.41,  2.53, -0.18, -2.78, -4.65, -5.5,\n",
    "     -5.04, -3.25, -0.75,  1.79,  3.88,  5.31,  5.2,   3.92,  1.74, -0.85,\n",
    "     -3.13, -4.71, -5.06, -4.26, -2.48, -0.13,  2.19,  4.07,  4.9,   4.64,\n",
    "      3.16,  1.17, -1.54, -3.26, -4.59, -4.64, -3.69, -1.83,  0.38,  2.76,\n",
    "      4.16,  4.58,  4.13,  2.45,  0.28, -1.8,  -3.53, -4.43, -4.31, -3.03,\n",
    "     -1.05,  1.06,  2.79,  3.97,  4.4,   3.37,  1.92, -0.14, -2.29, -3.7,\n",
    "     -4.28, -3.84, -2.44, -0.59,  1.27,  3.11,  3.9,   4.02,  2.85,  1.21,\n",
    "     -0.64, -2.51, -3.41, -3.84, -3.34, -1.75, -0.17,  1.85,  3.23,  3.72,\n",
    "      3.4,   2.54,  0.67, -1.13, -2.8,  -3.77, -3.65, -2.89, -1.43,  0.42,\n",
    "      2.2,   3.26,  3.42,  3.25,  1.88,  0.33, -1.35, -3.02, -3.41, -3.32,\n",
    "     -2.2,  -0.77,  0.92,  2.44,  3.31,  3.44,  2.77,  1.25, -0.13, -1.69, -2.78 ]\n",
    "a_errors = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amplitude as a function of time is given by the following model function:\n",
    "```\n",
    "# Model function for a pendulum as a one-dimensional,\n",
    "#     damped harmonic oscillator with zero initial speed:\n",
    "# x = time, y_0 = initial_amplitude, l = length of the string,\n",
    "# r = radius of the steel ball, g = gravitational acceleration, c = damping coefficient.\n",
    "def damped_harmonic_oscillator(s, a0, l, r, g, c):\n",
    "  # Effective length of the pendulum = length of the string + radius of the steel ball:\n",
    "  l_total = l + r\n",
    "  omega_0 = np.sqrt(g / l_total) # Phase speed of an undamped pendulum.\n",
    "  omega_d = np.sqrt(omega_0 ** 2 - c ** 2) # Phase speed of a damped pendulum.\n",
    "  return a0 * np.exp(-c * s) * (np.cos(omega_d * s) + c / omega_d * np.sin(omega_d * s))\n",
    "```\n",
    "\n",
    "Data container and fit object are created as usual:\n",
    "```\n",
    "# Create data container:\n",
    "data3 = XYContainer(t, a)\n",
    "data3.add_error(axis='x', err_val=t_errors)\n",
    "data3.add_error(axis='y', err_val=a_errors)\n",
    "data3.axis_labels = ('Time t (s)', 'Amplitude A (°)') \n",
    "\n",
    "# Create fit object from data and model function:\n",
    "fit = Fit(data3, damped_harmonic_oscillator)\n",
    "```\n",
    "\n",
    "The model contains a number of parameters defined by \"auxiliary measurements\".\n",
    "```\n",
    "# Relevant physical magnitudes and their uncertainties:\n",
    "lm, delta_lm = 10.000, 0.002  # length of the string, l = 10.0 +- 0.002 m\n",
    "rm, delta_rm = 0.052, 0.001  # radius of the steel ball, r = 0.052 +- 0.001 m\n",
    "# Amplitude of the steel ball at x=0 in degrees, a0m = 6 +- 1% degrees:\n",
    "a0m, delta_a0m = 6.0, 0.01  # Note that the uncertainty on a0m is relative to a0m.\n",
    "```\n",
    "\n",
    "The fit takes this into account by considering the corresponding parameters both as\n",
    "parameters of the fit and as additional data points.\n",
    "In *kafe2* such parameters restricted by measurements are considered with the help of the\n",
    "method *Fit.add_parameter_constraint()* and their uncertainties are propagated into\n",
    "the result of the fit:\n",
    "```\n",
    "# Constrain model parameters to measurements:\n",
    "fit.add_parameter_constraint(name='l', value=lm, uncertainty=delta_lm)\n",
    "fit.add_parameter_constraint(name='r', value=rm, uncertainty=delta_rm)\n",
    "fit.add_parameter_constraint(name='a0', value=a0m, uncertainty=delta_a0m, relative=True)\n",
    "```\n",
    "\n",
    "Alternatively, you could set the parameters to constant values with the method\n",
    "*Fit.fix_parameter()*;\n",
    "however, the uncertainties on the final result of the fit would then have to be calculated\n",
    "using classical error propagation.\n",
    "\n",
    "A problem with  non-linear fits is that there are often secondary minima of the cost\n",
    "function - convergence to the global minimum is not guaranteed.\n",
    "It is therefore necessary to select \"reasonable\" start parameters for the fit.\n",
    "This is done using the function *Fit.set_parameter_values()*:\n",
    "```\n",
    "g_initial = 9.81  # Initial guess for g.\n",
    "fit.set_parameter_values(g=g_initial, a0=a0m, l=lm, r=rm)\n",
    "```\n",
    "\n",
    "If the initial values are completely unknown, the fit should be repeated with a wide range\n",
    "of initial parameters to check that it consistently converges to the same minimum.\n",
    "\n",
    "Another means of improving convergence is to limit parameters to \"reasonable\" intervals.\n",
    "The parameters *a0*, *l*, and *r* are for example positive by definition.\n",
    "During the fit however they can become negative.\n",
    "The following code limits them to positive values:\n",
    "```\n",
    "fit.limit_parameter(\"a0\", lower=1e-6)\n",
    "fit.limit_parameter(\"l\", lower=1e-6)\n",
    "fit.limit_parameter(\"r\", lower=1e-6)\n",
    "```\n",
    "For technical reasons parameters can only be limited to closed intervals.\n",
    "As the lower limit a small value close to zero is specified.\n",
    "Because no upper value is specified the parameter limit is one-sided.\n",
    "It is also possible to define two-sided parameter limits:\n",
    "```\n",
    "fit.limit_parameter(\"g\", lower=9.71, upper=9.91)\n",
    "```\n",
    "The above limit is based on the assessment that results outside of these limits are\n",
    "very unlikely.\n",
    "It's also a good idea to limit parameters based on the physical properties of the system.\n",
    "For example the model function only yields real solutions for $c < \\frac{g}{l + r}$.\n",
    "This can be considered with the following code:\n",
    "```\n",
    "c_max = 0.9 * g_initial / (lm + rm)  # A little lower than our best guess for the limit.\n",
    "fit.limit_parameter(\"c\", lower=1e-6, upper=c_max)\n",
    "```\n",
    "\n",
    "After these preparations the fit can be performed as usual.\n",
    "The following code example also shows how to access the fit results via properties if\n",
    "they are to be processed further in the program or if a specific output is desired.\n",
    "```\n",
    "# Perform the fit\n",
    "fit.do_fit()\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "#fit.report(show_data=False, show_model=False, show_fit_results=True)\n",
    "\n",
    "# Custom printout of results:\n",
    "print(\"cost function at minimum: %.4g \" % fit.cost_function_value,\n",
    "    \" number of degrees of freedom:\", fit.ndf)\n",
    "print(\" --> probability: %.1f%%\" % (fit.chi2_probability * 100))\n",
    "print(\"parameter names:\\n\", fit.parameter_names)\n",
    "np.set_printoptions(precision=5, suppress=False)\n",
    "print(\"prameter values:\\n\", fit.parameter_values)\n",
    "print(\"parameter uncertainties:\\n\",fit.parameter_errors)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"correlation matrix:\\n\", fit.parameter_cor_mat )\n",
    "      \n",
    "# Optional: plot the fit results.\n",
    "plot = Plot(fit)\n",
    "plot.plot(fit_info=True)\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Construction of a Covariance Matrix from Individual Uncertainties\n",
    "---\n",
    "\n",
    "To be treated:\n",
    "  - dealing with complex uncertainties\n",
    "\n",
    "One of the strengths of _kafe2_ is the support for correlated uncertainties.\n",
    "This refers to contributions to uncertainties that influence some or all values in\n",
    "the same way - e.g. because they were recorded with the same measuring instrument\n",
    "that has a systematic uncertainty.\n",
    "Uncertainties that are shared between groups of measured values are very common.\n",
    "\n",
    "The following function is used to specify uncertainties:\n",
    "> `add_error**( [axis], err_val, name=None, correlation=0, relative=False)`  \n",
    "  Add an uncertainty source to the data container. Returns an error id which\n",
    "  uniquely identifies the created error source.  \n",
    "  **Parameters**  \n",
    "  • axis (str or int) – 'x'/0 or 'y'/1  \n",
    "  • err_val (float or iterable of float) – pointwise uncertainty/uncertainties for all data points  \n",
    "  • name (str or None) – unique name for this uncertainty source. If None, the name\n",
    "    of the error source will be set to a random alphanumeric string.  \n",
    "  • correlation (float) – correlation coefficient between any two distinct data points  \n",
    "  • relative (bool) – if True, err_val will be interpreted as a relative uncertainty  \n",
    "  **Returns** error name  \n",
    "  **Return type** str  \n",
    "\n",
    "It belongs to the container class, but can also be called via a fit class.\n",
    "With this rather simple interface, independent uncertainties as well as\n",
    "common absolute or relative uncertainties of data points can be specified.\n",
    "The specified uncertainties are converted into a covariance matrix of the data points.\n",
    "If the interface is called several times, the resulting covariance matrices are added\n",
    "together (in accordance with the rules of elementary error propagation).\n",
    "\n",
    "A very simple example will illustrate this.\n",
    "We consider the averaging of four values, which were carried out by two groups with different\n",
    "measuring methods.\n",
    "Each of the two groups gives two measurements;\n",
    "in the first group there is an absolute uncertainty common to the two measurements;\n",
    "the second group indicates a relative uncertainty correlated between its two measurements, e.g.\n",
    "caused by a scaling error.\n",
    "Furthermore, the measurements are based on a common (theoretical) assumption which leads to an\n",
    "absolute uncertainty common to all measurements.\n",
    "\n",
    "For this simple problem we use the simplest data structure of *kafe2*, the\n",
    "_IndexedContainer_, to provide the data:\n",
    "```\n",
    "from kafe2 import IndexedContainer\n",
    "idx_data = IndexedContainer([5.3, 5.2, 4.7, 4.8])\n",
    "```\n",
    "As model we choose a constant function:\n",
    "```\n",
    "# The very simple \"model\":\n",
    "def average (a):\n",
    "  return a\n",
    "```\n",
    "\n",
    "The uncertainties are then stated as follows\n",
    "                (Note: For an _IndexedContainer_, the _axis_ parameter is not required!):\n",
    "  1. each measurement has its own independent uncertainty\n",
    "   `err_stat = idx_data.add_error([.2, .2, .2, .2])`\n",
    "  2. the uncertainty common to the first two values\n",
    "   `err_syst12 = idx_data.add_error([.175, .175, 0., 0.], correlation = 1.)`\n",
    "  3. the relative uncertainty common to the last two values\n",
    "   `err_syst34 = idx_data.add_error([0., 0., .05, 0.05], correlation = 1., relative=True)`\n",
    "  4. the uncertainty common to all values\n",
    "   `err_syst = idx_data.add_error(0.15, correlation = 1.)`\n",
    "\n",
    "We should also provide suitable labels for the data:\n",
    "```\n",
    "idx_data.label = 'Test data'\n",
    "idx_data.axis_labels = [None,'Measured value (a.o.)']\n",
    "```\n",
    "\n",
    "The execution of the fit is well known by now:\n",
    "```\n",
    "# Set up the fit:\n",
    "ifit = Fit(idx_data, average)\n",
    "ifit.model_label = 'average value'\n",
    "\n",
    "# Perform the fit:\n",
    "ifit.do_fit()\n",
    "```\n",
    "\n",
    "The results can of course be obtained with the _report()_ function, if necessary also as a\n",
    "graphical representation:\n",
    "```\n",
    "# Report and plot results:\n",
    "ifit.report()\n",
    "p=Plot(ifit)\n",
    "p.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The labeling of the x-axis is not yet appropriate - only the indices of the measurements should\n",
    "appear here.\n",
    "With a little help from *matplotlib* this can be achieved.\n",
    "To do so, you have to access the *axis* object of the generated figure and make the appropriate\n",
    "adjustments.\n",
    "To do this, insert the following code after the line *p.plot()* before *plt.show()*:\n",
    "```\n",
    "# illustrate some a-posteriory fixes to plot layout by accessing the axis object\n",
    "_ax = p.axes[0]['main']\n",
    "_ax.set_xticks(range(4)) # Integer axis ticks\n",
    "```\n",
    "\n",
    "If a problem contains several contributions to the overall uncertainty, one would\n",
    "usually like to study the influence of individual components.\n",
    "For this purpose, one can comfortably work with the functions *disable_error()* and\n",
    "*enable_error()* and make appropriate fits:\n",
    "```\n",
    "print(\"disabling common sysytematic error\")\n",
    "idx_data.disable_error(err_syst)\n",
    "_ifit = Fit(idx_data, average)\n",
    "_ifit.do_fit()\n",
    "_ifit.report()\n",
    "#      do not forget to switch on again\n",
    "idx_data.enable_error(err_syst)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "# -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Application from the Real World: Fit of a Breit-Wigner Resonance\n",
    "---\n",
    "\n",
    "To be treated:\n",
    "  - dealing with complex uncertainties\n",
    "  - the creation of an appealing graphical output\n",
    "  - studying the influence of individual error components\n",
    "\n",
    "Typically, the uncertainties of the measurement data are much more complex than in the examples\n",
    "discussed so far.\n",
    "In most cases there are uncertainties in ordinate and abscissa, and in addition to the\n",
    "independent uncertainties of each data point there are common, correlated uncertainties for all\n",
    "of them.\n",
    "\n",
    "With the method *add_error()* or *add_matrix_error()* uncertainties can be specified on the 'x'\n",
    "and 'y' data, either in the form of independent or correlated, relative or absolute uncertainties\n",
    "of all or groups of measured values or by specifying the complete covariance or correlation matrix.\n",
    "All uncertainties specified in this way are included in the global covariance matrix for the fit.\n",
    "\n",
    "As an example, we consider measurements of a cross section as a function of the energy near a\n",
    "resonance.\n",
    "These are combined measurement data from the four experiments at CERN's LEP accelerator, which\n",
    "were corrected for effects caused by photon radiation:\n",
    "\n",
    "Measurements of the hadronic cross section $\\sigma_{e^+e^- \\to {\\rm hadrons}}$ as a function of\n",
    "the centre-of-mass energy $E$.\n",
    "```\n",
    "## Data:\n",
    "# Center-of-mass energy E (GeV)\n",
    "E = [ 88.387, 89.437, 90.223, 91.238, 92.059, 93.004, 93.916 ]\n",
    "E_errors = [ 0.005, 0.0015, 0.005, 0.003, 0.005, 0.0015, 0.005 ]\n",
    "ECor_abs = 0.0017  # correlated absolute errors\n",
    "\n",
    "# hadronic cross section with photonic corrections applied (nb)\n",
    "sig = [6.803, 13.965, 26.113, 41.364, 27.535, 13.362, 7.302 ]\n",
    "sig_errors = [ 0.036, 0.013, 0.075, 0.010, 0.088, 0.015, 0.045 ]\n",
    "sigCor_rel = 0.0007\n",
    "```\n",
    "\n",
    "As a model we use a modified Breit-Wigner resonance with a width dependent on the centre-of-mass\n",
    "energy (\"$s$-dependent width\", where $s = E_{CM}^2$):\n",
    "```\n",
    "## Model:\n",
    "# Breit-Wigner with s-dependent width\n",
    "def BreitWigner(E, s0 = 41.0, M = 91.2, G = 2.5):\n",
    "    s = E*E\n",
    "    Msq = M*M\n",
    "    Gsq = G*G\n",
    "    return s0*s*Gsq/((s-Msq)*(s-Msq)+(s*s*Gsq/Msq))\n",
    "```\n",
    "\n",
    "The data container with the uncertainties is created as follows:\n",
    "```\n",
    "BWdata= XYContainer(ECM, sig)\n",
    "# Add independent errors:\n",
    "error_name_sig = BWdata.add_error(axis='x', name = 'deltaE', err_val = E_errors )\n",
    "error_name_E = BWdata.add_error(axis='y', name = 'deltaSig', err_val = sig_errors )\n",
    "# Add fully correlated, absolute Energy errors:\n",
    "error_name_ECor = BWdata.add_error(axis='x', name='Ecor',err_val = ECor_abs, correlation = 1.)\n",
    "# Add fully correlated, relative cross section errors:\n",
    "error_name_sigCor = BWdata.add_error(axis='y', name='sigCor',\n",
    "                            err_val = sigCor_rel, correlation = 1., relative=True)\n",
    "```\n",
    "\n",
    "Whether the uncertainties are independent or correlated is determined by the parameter\n",
    "*correlation*;\n",
    "for independent uncertainties it is zero, for uncertainties common to all data entries it is one.\n",
    "Values between 0. and 1. are also allowed;\n",
    "however, in practice the covariance matrix for describing the overall uncertainty is usually\n",
    "composed of uncorrelated and fully correlated components.\n",
    "The names given in the *add_error* function allow the individual error components to be accessed\n",
    "later.\n",
    "\n",
    "Fit and result output follow the usual procedure:\n",
    "```\n",
    "BWfit = Fit(BWdata, BreitWigner)\n",
    "BWfit.do_fit()\n",
    "BWfit.report()\n",
    "# Optional: plot the fit results\n",
    "BWplot = Plot(BWfit)\n",
    "BWplot.plot(fit_info=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Enhancement of the graphical output**\n",
    "To ensure that the type of data is clearly described, suitable names should be assigned.\n",
    "The lines below must be inserted before the *Fit* object is created.\n",
    "```\n",
    "BWdata.label = 'QED-corrected hadronic cross-sections'\n",
    "BWdata.axis_labels = ('CM Energy (GeV)', '$\\sigma_h$ (nb)' )\n",
    "```\n",
    "Alternatively the following lines can be inserted after creating the fit object:\n",
    "```\n",
    "BWfit.data_container.label = 'QED-corrected hadronic cross-sections'\n",
    "BWfit.data_container.axis_labels = ('CM Energy (GeV)', r'$\\sigma_h$ (nb)')\n",
    "```\n",
    "\n",
    "A suitable name for the model should also be set in the legend for the graphical output.\n",
    "To do this, insert the line below after the *Fit* object has been created:\n",
    "```\n",
    "BWfit.model_label = 'Beit-Wigner with s-dependent width'\n",
    "```\n",
    "\n",
    "If a nicely set expression for the model function is desired, LaTeX names can be set for the\n",
    "model, the parameters and the model function:\n",
    "```\n",
    "# Set LaTeX names for printout in info-bo:\n",
    "BWfit.assign_parameter_latex_names(E='E', s0=r'{\\sigma^0}', M=r'{M_Z}', G=r'{\\Gamma_Z}')\n",
    "BWfit.assign_model_function_latex_name(r'\\sigma^{\\rm ew}_{e^+e^-\\to{\\rm hadrons}}')\n",
    "BWfit.assign_model_function_latex_expression(\n",
    "               r'{s0}\\frac{{ {E}^2{G}^2}}{{({E}^2-{M}^2)^2+({E}^4{G}^2/{M}^2)}}')\n",
    "```\n",
    "Note: The doubling of the brackets \"{\" and \"}\" is necessary because in *kafe2*, similar to the\n",
    "Python *format* function, they are also used to pass parameters.\n",
    "\n",
    "The previous example showed how to modify the band showing the model uncertainty:\n",
    "```\n",
    "BWplot.customize('model_error_band', 'label', [r'$\\pm 1\\sigma$'])\n",
    "```\n",
    "In this example, however, the model uncertainty is extremely small (well below 0.1%) and\n",
    "therefore not visible in the graph.\n",
    "You can suppress the output in the legend with the following specification:\n",
    "```\n",
    "BWplot.customize('model_error_band', 'label', [None])\n",
    "```\n",
    "Sometimes the uncertainty band is covered by the line;\n",
    "in such cases a dashed or dotted line should be used for the model:\n",
    "```\n",
    "BWplot.customize('model_line', 'linestyle', [':'])\n",
    "```\n",
    "\n",
    "The edges of the plot can also be adjusted.\n",
    "This can be done via the properties *x_range* and *y_range* od the Plot class:\n",
    "```\n",
    "BWplot.x_range = (88, 94)\n",
    "BWplot.y_range = (0, 45)\n",
    "```\n",
    "\n",
    "Since this is a non-linear fit, the profile likelihood and confidence contours should\n",
    "still be displayed.\n",
    "The following line must be inserted before *plt.show()*:\n",
    "```\n",
    "ContoursProfiler(BWfit).plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "```\n",
    "!!! Patience: the calculation of the contours is computationally complex and takes a certain\n",
    "amount of time!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' the data for the Breit-Wigner example'''\n",
    "# Center-of-mass energies E (GeV)\n",
    "ECM = [ 88.387, 89.437, 90.223, 91.238, 92.059, 93.004, 93.916 ]\n",
    "E_errors = [ 0.005, 0.0015, 0.005, 0.003, 0.005, 0.0015, 0.005 ]\n",
    "ECor_abs = 0.0017  # correlated absolute errors\n",
    "\n",
    "# hadronic cross sections with photonic corrections applied (nb)\n",
    "sig = [6.803, 13.965, 26.113, 41.364, 27.535, 13.362, 7.302 ]\n",
    "sig_errors = [ 0.036, 0.013, 0.075, 0.010, 0.088, 0.015, 0.045 ]\n",
    "sigCor_rel = 0.0007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# enter the code from above here\n",
    "# -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study of the influence of individual error components**\n",
    "To investigate the influence of individual error components on the result, individual sources of\n",
    "uncertainty can be switched off with the method *disable_error()* and a new fit can be performed,\n",
    "shown here for the correlated uncertainty of the center-of-mass energies:\n",
    "```\n",
    "print('!!!  disabling error component ', error_name_ECor)\n",
    "BWfit.disable_error(error_name_ECor)\n",
    "BWfit.do_fit()\n",
    "BWfit.report(show_data=False, show_model=False)\n",
    "\n",
    "# do not forget to switch on again !\n",
    "print('!!!  re-enabling error component ', error_name_ECor)\n",
    "BWfit.enable_error(error_name_ECor)\n",
    "\n",
    "#### fallback option with new fit object\n",
    "#print('!!!  disabling error component ', error_name_ECor)\n",
    "#BWdata.disable_error(error_name_ECor)\n",
    "#_fit = Fit(BWdata, BreitWigner)\n",
    "#_fit.do_fit()\n",
    "#_fit.report(show_data=False, show_model=False)\n",
    "#BWdata.enable_error(error_name_ECor)\n",
    "```\n",
    "The result is almost identical to the previous one, only the uncertainty of the mass is now smaller.\n",
    "This was also to be expected, because a correlated change of all energies should not influence\n",
    "the width or height of the resonance.\n",
    "\n",
    "With the method `enable_error(error_name_ECor)` the uncertainty source is reactivated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try it out here\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 6. Fit to Histogram Data\n",
    "***\n",
    "\n",
    "In principle, the fit of a distribution density to a frequency distribution can also be\n",
    "understood as a functional fit.\n",
    "However, there are some special features that must be taken into account:\n",
    "\n",
    "- The function value for a bin corresponding to the value of a distribution density (PDF=Particle\n",
    "  Density Function) corresponds to the integral of the PDF via the bin\n",
    "- The uncertainty of a bin entry results from the Poisson distribution, which can only be\n",
    "  approximated by a Gaussian distribution for very large numbers of entries per bin.\n",
    "\n",
    "Therefore *kafe2* offers a special method to fit a distribution density to histograms, the\n",
    "classes *HistContainer* to store the histogram data and *HistFit* to perform the fit:\n",
    "```\n",
    "from kafe2 import HistContainer, HistFit\n",
    "```\n",
    "\n",
    "Twice the negative logarithm of the Poisson likelihood is used as the cost function to evaluate\n",
    "the agreement of the adjusted PDF with the bin entries in the frequency distribution, other\n",
    "options are configurable.\n",
    "\n",
    "In this simple example, we use the frequency distribution of Gaussian-distributed random numbers\n",
    "to which a Gaussian distribution is fitted.\n",
    "```\n",
    "def normal_distribution_pdf(x, mu, sigma):\n",
    "  return np.exp(-0.5 * ((x - mu) / sigma) ** 2) / np.sqrt(2.0 * np.pi * sigma** 2)\n",
    "```\n",
    "\n",
    "The data is generated randomly from the standard normal distribution:\n",
    "```\n",
    "# create a random dataset of 100 random values,\n",
    "#  following a standard normal distribution with mu=0 and sigma=1\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "```\n",
    "\n",
    "The data container and the fit object are created in the same way as in the previous examples:\n",
    "```\n",
    "# Create a histogram from the dataset by specifying the bin range and the number of bins.\n",
    "# Alternatively the bin edges can be set.\n",
    "histogram = HistContainer(n_bins=10, bin_range=(-5, 5), fill_data=data)\n",
    "\n",
    "# create the Fit object by specifying a density function\n",
    "fit = HistFit(data=histogram, model_density_function=normal_distribution_pdf)\n",
    "```\n",
    "\n",
    "Carrying out the fit and outputting the results are no different from the procedure used in the\n",
    "previous examples:\n",
    "```\n",
    "# do the fit\n",
    "fit.do_fit()\n",
    "\n",
    "# Optional: print a report to the terminal\n",
    "fit.report()\n",
    "\n",
    "# Optional: create a plot and show it\n",
    "phist = Plot(fit)\n",
    "phist.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "At this point we should take another look at the possibilities for customizing the graphical output.\n",
    "The plot adapter for histograms knows the values *data*, *model* and *model_density* as *plot_type*.\n",
    "By calling `print(phist.get_keywords(<plot_type>))` the adjustable parameters can be retrieved.\n",
    "Here is a suggestion for code to customize the graphic output, which must be placed before the\n",
    "*phist.plot()* command:\n",
    "```\n",
    "## reprise: plot customization\n",
    "#    data\n",
    "phist.customize('data', 'label', [\"random Gaussian data\"] )\n",
    "phist.customize('data', 'marker', ['o'])\n",
    "phist.customize('data', 'markersize', [5])\n",
    "phist.customize('data', 'color', ['blue'])\n",
    "phist.customize('data', 'ecolor', ['blue'])\n",
    "#    model\n",
    "phist.customize('model_density', 'label', [\"Gaussian PDF\"])\n",
    "phist.customize('model_density', 'color', [\"black\"])\n",
    "phist.customize('model', 'label', [\"entries per bin\"])\n",
    "phist.customize('model', 'facecolor', [\"lightgrey\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try here\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7. Likelihood fits\n",
    "***\n",
    "\n",
    "If only few measurements are available it is not possible to obtain a meaningful frequency\n",
    "distribution because a coarse division into bins would distort the measurements, while a too\n",
    "fine division would lead to bins with very few or even zero entries.\n",
    "The method already used above for fitting a distribution density to a frequency distribution is\n",
    "then not applicable.\n",
    "In such cases, a direct fit to the unbinned data using the maximum likelihood method is used.\n",
    "This procedure is implemented in *kafe2*.\n",
    "For this the appropriate classes must be imported:\n",
    "```\n",
    "from kafe2.fit import UnbinnedContainer, UnbinnedFit\n",
    "```\n",
    "\n",
    "In this example we use 160 individual measurements of the lifetime of muons from cosmic\n",
    "radiation stopped in a detector.\n",
    "The frequency distribution is an exponential distribution over flat ground:\n",
    "\n",
    "```\n",
    "def pdf(t, tau=2.2, fbg=0.1, a=1., b=9.75):\n",
    "  \"\"\"\n",
    "  Probability density function for the decay time of a myon.\n",
    "  The pdf is normalized to an integral of one for the interval (a, b).\n",
    "  :param t: decay time\n",
    "  :param fbg: background\n",
    "  :param tau: expected mean of the decay time\n",
    "  :param a: the minimum decay time which can be measured\n",
    "  :param b: the maximum decay time which can be measured\n",
    "  :return: probability for decay time x\n",
    "  \"\"\"\n",
    "  pdf1 = np.exp(-t / tau) / tau / (np.exp(-a / tau) - np.exp(-b / tau))\n",
    "  pdf2 = 1. / (b - a)\n",
    "  return (1 - fbg) * pdf1 + fbg * pdf2\n",
    "```\n",
    "\n",
    "Please note that the frequency distribution for all possible parameter values must be normalized\n",
    "to one!\n",
    "\n",
    "There is only one small particularity regarding the fit procedure:\n",
    "due to the small number of observations, the background portion is subject to a large uncertainty\n",
    "and can therefore even become negative during the fit.\n",
    "To avoid this \"unphysical\" range of the parameter, the previously shown method\n",
    "`fit.limit_parameter(<name>, lower=<min>, upper=<max>)` can be used.\n",
    "\n",
    "All further steps in the following sample code are already known:\n",
    "```\n",
    "data = UnbinnedContainer(dT) # create the kafe data object\n",
    "data.label = 'lifetime measurements'\n",
    "data.axis_labels = ('Myon Life Time ' r'$\\tau$' ' (µs)','Density' )\n",
    "\n",
    "# create the fit object and set the pdf for the fit\n",
    "LLfit = UnbinnedFit(data=data, model_density_function = pdf)\n",
    "\n",
    "# assign latex names for model and parameters for nicer display\n",
    "LLfit.model_label = 'Exponential decay + flat background'\n",
    "LLfit.assign_parameter_latex_names(t='t', tau=r'\\tau', fbg='f', a='a', b='b')\n",
    "LLfit.assign_model_function_latex_expression(\"\\\\frac{{ (1-{fbg}) \\, e^{{-{0}/{tau}}}}}\"\n",
    "    \"{{{tau}(e^{{-{a}/{tau}}}-e^{{-{b}/{tau}}})}} + \\\\frac{{ {fbg} }} {{ {b}-{a} }}\")\n",
    "\n",
    "# Fix the parameters a and b ...\n",
    "a = 1.0\n",
    "b = 11.5\n",
    "LLfit.fix_parameter(\"a\", a)\n",
    "LLfit.fix_parameter(\"b\", b)\n",
    "# ... and limit parameter fbg\n",
    "LLfit.limit_parameter(\"fbg\", lower=0., upper=1.)\n",
    "\n",
    "LLfit.do_fit()  # perform the fit\n",
    "LLfit.report(asymmetric_parameter_errors=True)\n",
    "\n",
    "pLL = Plot(LLfit)  # create a plot object\n",
    "pLL.x_range = [a, b]\n",
    "pLL.plot(fit_info=True, asymmetric_parameter_errors=True)  # plot the data and the fit\n",
    "#pLL.axes[0]['main'].set_xlabel('Life time '+r'$\\tau$'+' (µs)', size='large')  # overwrite the x-axis label\n",
    "\n",
    "cpfLL = ContoursProfiler(LLfit, profile_subtract_min=False)  # Optional: create a contours profile\n",
    "cpfLL.plot_profiles_contours_matrix(parameters=['tau', 'fbg'])  # Optional: plot the contour matrix for tau and fbg\n",
    "\n",
    "plt.show()  # show the plot(s)\n",
    "```\n",
    "\n",
    "Of particular interest is the special mode of graphical representation of the data,\n",
    "where each measured value is represented by a line.\n",
    "The density of the lines per unit length corresponds to the distribution density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' the data for the myon life time example'''\n",
    "# real data from measurement with a Water Cherenkov detector (\"Kamiokanne\")\n",
    "dT = [7.42, 3.773, 5.968, 4.924,  1.468,  4.664,  1.745,  2.144,  3.836,  3.132,\n",
    "  1.568,  2.352,  2.132,  9.381,  1.484,  1.181,  5.004,  3.06,   4.582,  2.076,\n",
    "  1.88,   1.337,  3.092,  2.265,  1.208,  2.753,  4.457,  3.499,  8.192,  5.101,\n",
    "  1.572,  5.152,  4.181,  3.52,   1.344, 10.29,   1.152,  2.348,  2.228,  2.172,\n",
    "  7.448,  1.108,  4.344,  2.042,  5.088,  1.02,   1.051,  1.987,  1.935,  3.773,\n",
    "  4.092,  1.628,  1.688,  4.502,  4.687,  6.755,  2.56,   1.208,  2.649,  1.012,\n",
    "  1.73,   2.164,  1.728,  4.646,  2.916,  1.101,  2.54,   1.02,   1.176,  4.716,\n",
    "  9.671,  1.692,  9.292, 10.72,   2.164,  2.084,  2.616,  1.584,  5.236,  3.663,\n",
    "  3.624,  1.051,  1.544,  1.496,  1.883,  1.92,   5.968,  5.89,   2.896,  2.76,\n",
    "  1.475,  2.644,  3.6,    5.324,  8.361,  3.052,  7.703,  3.83,   1.444,  1.343,\n",
    "  4.736,  8.7,    6.192,  5.796,  1.4,    3.392,  7.808,  6.344,  1.884,  2.332,\n",
    "  1.76,   4.344,  2.988,  7.44,   5.804,  9.5,    9.904,  3.196,  3.012,  6.056,\n",
    "  6.328,  9.064,  3.068,  9.352,  1.936,  1.08,   1.984,  1.792,  9.384, 10.15,\n",
    "  4.756,  1.52,   3.912,  1.712, 10.57,   5.304,  2.968,  9.632,  7.116, 1.212,\n",
    "  8.532,  3.000,  4.792,  2.512,  1.352,  2.168,  4.344,  1.316,  1.468, 1.152,\n",
    "  6.024,  3.272,  4.96,  10.16,   2.14,   2.856, 10.01,   1.232, 2.668, 9.176 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try the likelihood fit here\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 8. Multi-Fits:\n",
    "### simultaneous fit of model functions to different data sets\n",
    "***\n",
    "Very often the models are too complex to determine all parameters in a fit to a single model.\n",
    "Instead model parameters are frequently the result of several fits,\n",
    "or the same parameter occurs in different measurement series.\n",
    "\n",
    "For such cases *kafe2* offers the possibility to perform several fits of different models with\n",
    "common parameters to different data sets.\n",
    "\n",
    "For this purpose, the *MultiFit* package must also be imported:\n",
    "```\n",
    "from kafe2 import MultiFit\n",
    "```\n",
    "\n",
    "As a simple example, we consider the determination of an ohmic resistance at room temperature,\n",
    "which heats up at higher current flow and thus changes its resistance according to its\n",
    "temperature coefficient.\n",
    "Therefore, in addition to the current through the resistor, the temperature is measured for each\n",
    "given voltage value.\n",
    "Triplets of measured values must therefore be evaluated.\n",
    "\n",
    "The temperature dependence is described empirically by a simple quadratic model:\n",
    "```\n",
    "# empirical model for T(U): a parabola\n",
    "def empirical_T_U_model(U, p2=1.0, p1=1.0, p0=0.0):\n",
    "    # use quadratic model as empirical temperature dependence T(U)\n",
    "    return p2 * U**2 + p1 * U + p0\n",
    "```\n",
    "\n",
    "The resistance as a function of temperature is given by the temperature coefficient $\\alpha$ and\n",
    "is modeled as follows\n",
    "```\n",
    "# model of current-voltage dependence I(U) for a heating resistor\n",
    "def I_U_model(U, R0=1., alph=0.004, p2=1.0, p1=1.0, p0=0.0):\n",
    "    # use quadratic model as empirical temperature dependence T(U)\n",
    "    t_ref = 0.\n",
    "    _delta_t = empirical_T_U_model(U, p2, p1, p0) - t_ref\n",
    "    # plug the temperature into the model\n",
    "    return U / (R0 * (1.0 + _delta_t * alph))\n",
    "```\n",
    "\n",
    "So in this case the model for resistance contains the first model for the dependence of\n",
    "temperature on the current determined by the applied voltage.\n",
    "\n",
    "Here is the data for this example:\n",
    "```\n",
    "# the data\n",
    "U = [ 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5,\n",
    "      6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0 ]\n",
    "I = [ 0.5,  0.89, 1.41, 1.67, 2.3,  2.59, 2.77, 3.57, 3.94,  4.24, 4.73,\n",
    "      4.87, 5.35, 5.74, 5.77, 6.17, 6.32, 6.83, 6.87, 7.17 ]\n",
    "T = [ 20.35, 20.65, 22.25, 23.65, 26.25, 27.85, 29.85, 34.25, 37.75, 41.95,\n",
    "     44.85, 50.05, 54.25, 60.55, 65.05, 69.95, 76.85, 81.55, 85.45, 94.75 ]\n",
    "sigU, sigI, sigT = 0.2, 0.1, 0.5 # uncertainties\n",
    "```\n",
    "\n",
    "The Fit procedure is hardly different from the procedure presented so far.\n",
    "First, the data containers and fits for the two models are defined as:\n",
    "```\n",
    "# Step 1: construct the singular data containers and fit objects\n",
    "TU_data = XYContainer(U,T)\n",
    "TU_data.label = 'Temperature data'\n",
    "TU_data.axis_labels = ['Voltage (V)','Temperature (°C)']\n",
    "fit_1 = Fit(TU_data, model_function=empirical_T_U_model)\n",
    "fit_1.model_label = 'Parametrization'\n",
    "\n",
    "IU_data = XYContainer(U,I)\n",
    "IU_data.label = 'Current data'\n",
    "IU_data.axis_labels = ['Voltage (V)','Current (A)']\n",
    "fit_2 = Fit(IU_data, model_function=I_U_model)\n",
    "fit_2.model_label = 'Temperature-dependent conductance'\n",
    "\n",
    "```\n",
    "\n",
    "Then both fits are combined to a *MultiFit*.\n",
    "```\n",
    "# Step 2: construct a MultiFit object\n",
    "multi_fit = MultiFit(fit_list=[fit_1, fit_2], minimizer='iminuit')\n",
    "```\n",
    "Only now are the uncertainties added - this time to the fit objects.\n",
    "This also allows the uncertainties on the x-axis, which are common to both data sets, to be taken\n",
    "into account.\n",
    "```\n",
    "# Step 3: Add errors (to the fit object in this case)\n",
    "multi_fit.add_error(sigT, 0, axis='y')  # declare errors on T\n",
    "multi_fit.add_error(sigI, 1, axis='y')  # declare errors on I\n",
    "multi_fit.add_error(sigU, 'all', axis='x') # shared error on x axis\n",
    "```\n",
    "\n",
    "The next step is to define meaningful names for the output:\n",
    "```\n",
    "# (Optional): assign names for models and parameters\n",
    "multi_fit.assign_parameter_latex_names(\n",
    "    U='U', p2='p_2', p1='p_1', p0='p_0', R0='R_0', alph=r'\\alpha_\\mathrm{T}')\n",
    "multi_fit.assign_model_function_expression('{p2}*{U}^2 + {p1}*{U} + {p0}', fit_index=0)\n",
    "multi_fit.assign_model_function_latex_expression(r'{p2}\\,{U}^2 + {p1}\\,{U} + {p0}', fit_index=0)\n",
    "multi_fit.assign_model_function_expression('{U} / ({R0} * (1 + ({p2}*{U}^2 + {p1}*{U} + {p0}) * {alph}))', fit_index=1)\n",
    "multi_fit.assign_model_function_latex_expression(r'\\frac{{{U}}}{{{R0} \\cdot (1 + ({p2}{U}^2 + {p1}{U} + {p0}) \\cdot {alph})}}', fit_index=1)\n",
    "```\n",
    "\n",
    "The rest works the same way as before:\n",
    "```\n",
    "# Step 4: do the fit\n",
    "multi_fit.do_fit()\n",
    "\n",
    "# (Optional): print the results\n",
    "multi_fit.report()\n",
    "\n",
    "# (Optional): plot the results\n",
    "plot = Plot(multi_fit, separate_figures=True)\n",
    "plot.customize('data', 'marker', ['.','.'])\n",
    "plot.customize('data', 'markersize', [6,6])\n",
    "\n",
    "plot.plot()\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# enter own code here\n",
    "# -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}