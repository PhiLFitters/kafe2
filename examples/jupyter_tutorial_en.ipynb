{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Jupyter notebook tutorial:\n",
    "#    Fitting models to data with *kafe2*\n",
    "\n",
    "                                                GÃ¼nter Quast, April 2020\n",
    "                                                Cedric Verstege, August 2020\n",
    "---\n",
    "## Jupyter notebook fundamentals\n",
    "\n",
    "This file of type `.ipynb` contains a tutorial as a `Jupyter notebook`.\n",
    "`Jupyter` provides a browser interface with a (simple) development environment for `python` code and\n",
    "and explanatory texts in intuitive *Markdown* format.\n",
    "The input of formulas in *LaTeX* format is also supported.\n",
    "\n",
    "A summary of the most important commands for using *jupyter* as a working environment can be\n",
    "found in the notebook\n",
    "[*JupyterCheatsheet.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/JupyterCheatsheet.ipynb)\n",
    "(German).\n",
    "Basics for statistical data analysis can be found in the notebooks\n",
    "[*IntroStatistik.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/IntroStatistik.ipynb)\n",
    "(German) and\n",
    "[*Fehlerrechnung.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/Fehlerrechnung.ipynb) (German).\n",
    "\n",
    "In *Jupyter*, code and text are entered into individual cells.\n",
    "Active cells are indicated by a blue bar in the margin.\n",
    "They can be in two states: in edit mode the input field is white, in command mode it is grayed out.\n",
    "Clicking in the border area selects the command mode, clicking in the text field of a code cell\n",
    "switches to edit mode.\n",
    "The `esc` key can also be used to leave the edit mode.\n",
    "\n",
    "Pressing `a` in command mode creates a new empty cell above the active cell, `b` creates one below.\n",
    "Entering `dd` deletes the corresponding cell.\n",
    "\n",
    "Cells can be either of the type `Markdown` or `Code`.\n",
    "Entering `m` in command mode sets the type Markdown, entering `y` selects the type Code.\n",
    "\n",
    "The cell content is processed - i.e. setting text or executing code - by entering `shift+return`,\n",
    "or `alt+return` if a new, empty cell should also be created.\n",
    "\n",
    "The settings mentioned here as well as the insertion, deletion or execution of cells can also be\n",
    "executed via the pull-down menu at the top.\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overview: *kafe*2\n",
    "***\n",
    "\n",
    "\n",
    "*kafe*2 is an extended version of the *kafe* package developed since 2012 for the fitting of model\n",
    "functions to data.\n",
    "\n",
    "It supports different data types like simple indexed data, two-dimensional data points (one size\n",
    "*\"x\"* and one dependent size *\"y\"*) and frequency distributions (histograms).\n",
    "Uncertainties of both dependent and independent quantities and, if applicable, their correlations\n",
    "are supported.\n",
    "For this purpose, the global covariance matrix is created from different types of specified\n",
    "uncertainties and taken into account in the fitting.\n",
    "Compared to many other fitting tools, this possibility is a unique feature of *kafe(2)*.\n",
    "\n",
    "Simultaneous fitting of several models is also supported. Each with its own and additionally all or\n",
    "several common parameters to different data sets (\"Multi-Fit\").\n",
    "\n",
    "To minimize the distance between data and model function(s) numerical methods are applied, which\n",
    "are derived from the open source, *python*-based software environment *scipy* or the *MINUIT*\n",
    "package developed at CERN.\n",
    "The respective minimized distance dimension (or the \"cost function\") is equal to the negative\n",
    "natural logarithm of the likelihood function for the data and the given model multiplied by a\n",
    "factor of two ($-2\\,\\ln{\\cal L}$).\n",
    "For Gaussian uncertainties of the data points, this corresponds to the method\n",
    "of the least squares (also called \"$\\chi^2$ method\"). Others, on the likelihood principle\n",
    "based cost functions for the fitting of probability densities to histograms or indexed data are\n",
    "also available.\n",
    "\n",
    "For the determination of the uncertainties on the parameters of the fitted model, the profile\n",
    "likelihood method is provided, with which confidence intervals for the individual parameters as\n",
    "well as two-dimensional confidence contours for pairs of parameters can be determined.\n",
    "\n",
    "*kafe2* contains a stand-alone application *kafe2go*, which allows fittings without the creation of\n",
    "own code; data, model function and options are specified in a file in yaml format:\n",
    "\n",
    "`kafe2go <name>.yaml`\n",
    "\n",
    "*kafe2* can also be used much more flexibly via a *python* interface.\n",
    "This tutorial gives an introduction to the possibilities.\n",
    "In general the procedure is as follows:\n",
    "\n",
    "  - Definition and initialization of a data container for the respective fitting (classes\n",
    "    IndexedContainer, XYContainer, HistContainer, UnbinnedContainer)\n",
    "  - Creation of a suitable object to perform the fitting that connects the data container to a model\n",
    "    (the general class _Fit_ or specialized classes _IndexedFit_, _XYFit_, _HistFit_, _UnbinnedFit_)\n",
    "  - Implementation of the fitting by means of `<Fit_Object>.do_fit()` and output the results to the\n",
    "    console using `<Fit_Object>.report()` or by directly accessing the result variables of the fit\n",
    "    object\n",
    "  - If necessary, generation and display of results graphics with the generic class *Plot*.\n",
    "\n",
    "**The following examples show the actual procedure.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### General settings and useful packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import division, print_function  # python2-compatibility\n",
    "import sys, os\n",
    "\n",
    "# Lines with % or %% at the beginning are so-called \"magic commands\",\n",
    "# that specify the cell type or options for displaying graphics\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports and presets for *kafe2*:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kafe2 import config, XYContainer, Fit, Plot\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# set better default figure size for kafe2\n",
    "# plt.rcParams['figure.figsize']=[12., 5.]\n",
    "#        !!!  must be done after importing kafe2 (will else be overwritten)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 1. Simple example for fitting mit `kafe`2\n",
    "***\n",
    "\n",
    "The following code illustrates the fitting of functions with the `kafe2` fitting tool\n",
    "\n",
    "```\n",
    "# Create an XYContainer object to hold the xy data for the fit.\n",
    "xy_data = XYContainer(x_data=[1.0, 2.0, 3.0, 4.0],\n",
    "                      y_data=[2.3, 4.2, 7.5, 9.4])\n",
    "# x_data and y_data are combined depending on their order.\n",
    "# The above translates to the points (1.0, 2.3), (2.0, 4.2), and (4.0, 9.4).\n",
    "\n",
    "# Important: Specify uncertainties for the data.\n",
    "xy_data.add_error(axis='x', err_val=0.1)\n",
    "xy_data.add_error(axis='y', err_val=0.4)\n",
    "\n",
    "# Create an Fit object from the xy data container.\n",
    "# By default, a linear function f=a*x+b will be used as the model function.\n",
    "line_fit = Fit(xy_data)\n",
    "\n",
    "# Perform the fit: Find values for a and b that minimize the\n",
    "#     difference between the model function and the data.\n",
    "line_fit.do_fit()  # This will throw an exception if no errors were specified.\n",
    "\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "line_fit.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "plot = Plot(fit_objects=line_fit)  # Create a kafe2 plot object.\n",
    "plot.plot()  # Do the plot.\n",
    "\n",
    "# Show the fit result.\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Paste the code into the empty cell below and execute it by pressing `shift+return`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# simple example: straight line adjustment with kafe2\n",
    "# -> insert code here\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Correlated uncertainties\n",
    "***\n",
    "\n",
    "To illustrate the possibilities for dealing with uncertainties, we add a further correlated\n",
    "uncertainty of the dependent quantities *y*:\n",
    "```\n",
    "xy_data.add_error(axis='y', err_val=0.3, correlation=1.)\n",
    "```\n",
    "\n",
    "Insert this line in the above code.\n",
    "You can make the output a bit clearer by omitting the output of the data and the model.\n",
    "To do this, modify the parameters of the `report()` method:\n",
    "```\n",
    "line_fit.report(show_data=false, show_model=false)\n",
    "```\n",
    "Now repeat the fit.\n",
    "\n",
    "As expected, such an uncertainty common to all data points does not affect the gradient of the\n",
    "straight line, but only the parameter *b*, whose uncertainty now becomes greater - corresponding\n",
    "to the square root of the square uncertainty of +/-0.58 from the original fit and the additional\n",
    "correlated uncertainty of 0.40.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Copy and extend code from the previous example\n",
    "# ->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 2. Comparison of two different models\n",
    "***\n",
    "\n",
    "Simple models with linear parameters are not sufficient in practice.\n",
    "The following example shows the fitting of a linear and an exponential model to the same data.\n",
    "\n",
    "Definition of two model functions:\n",
    "```\n",
    "# To define a model function for kafe2 simply write it as a python function\n",
    "def linear_model(x, a, b):\n",
    "    # Our first model is a simple linear function\n",
    "    return a * x + b\n",
    "\n",
    "def exponential_model(x, A0=1., x0=5.):\n",
    "    # Our second model is a simple exponential function\n",
    "    # The kwargs in the function header specify initial parameter defaults.\n",
    "    return A0 * np.exp(x/x0)\n",
    "```\n",
    "\n",
    "Here the definition of the data as kafe2 XYContainer:\n",
    "```\n",
    "# the data for this exercise\n",
    "x = [19.8, 3.0, 5.1, 16.1, 8.2,  11.7, 6.2, 10.1]\n",
    "y = [23.2, 3.2, 4.5, 19.9, 7.1, 12.5, 4.5, 7.2]\n",
    "data2 = XYContainer(x_data = x, y_data = y)\n",
    "data2.add_error(axis='x', err_val = 0.3)\n",
    "data2.add_error(axis='y', err_val = 0.15, relative = True)\n",
    "```\n",
    "\n",
    "So that the data can be clearly identified in the graphical output later, names for the data\n",
    "record and the axis labels are also set:\n",
    "```\n",
    "data2.label = 'data points'\n",
    "data2.axis_labels=['x-Wert','y-Wert']\n",
    "```\n",
    "\n",
    "Then one fit object for each model function and with the same data is created:\n",
    "```\n",
    "# Create 2 Fit objects with the same data but with different model functions\n",
    "linear_fit = Fit(data2, model_function=linear_model)\n",
    "exponential_fit = Fit(data2, model_function=exponential_model)\n",
    "```\n",
    "\n",
    "To make everything look better, we define LaTeX expressions for the functions, the names of the\n",
    "parameters and the legend in the graphical output:\n",
    "\n",
    "```\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit.assign_parameter_latex_names(a='a', b='b')\n",
    "linear_fit.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "linear_fit.model_label = 'lineares Modell'\n",
    "exponential_fit.assign_parameter_latex_names(A0='A_0', x0='x_0')\n",
    "exponential_fit.assign_model_function_latex_expression(\"{A0} e^{{{x}/{x0}}}\")\n",
    "exponential_fit.model_label = 'exponentielles Modell'\n",
    "```\n",
    "\n",
    "The code to perform the fits is as follows:\n",
    "```\n",
    "# Perform the fits.\n",
    "linear_fit.do_fit()\n",
    "exponential_fit.do_fit()\n",
    "\n",
    "# Optional: Print out a report on the result of each fit.\n",
    "linear_fit.report()\n",
    "exponential_fit.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p = Plot(fit_objects=[linear_fit, exponential_fit], separate_figures=False)\n",
    "p.plot(fit_info=True)\n",
    "\n",
    "# Show the fit results.\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Paste the code into the empty cell below and execute it by pressing 'shift+return'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Comparison of two models with kafe2\n",
    "# -> insert code here\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Hypothesis test to assess the models\n",
    "***\n",
    "\n",
    "The graphical output does not clearly indicate which of the models is acceptable.\n",
    "For this purpose, a hypothesis test can be performed, which indicates the so-called $\\chi^2$\n",
    "probability - i.e. the probability of obtaining a worse value of $\\chi^2$ at the minimum than the\n",
    "observed one.\n",
    "\n",
    "It is calculated from the cumulative distribution density of the Chi2 function:\n",
    "```\n",
    "from scipy import stats\n",
    "\n",
    "def chi2prob(chi2, ndf):\n",
    "  \"\"\" chi2-probability\n",
    "\n",
    "    Args:\n",
    "      * chi2: chi2 value\n",
    "      * ndf: number of degrees of freedom\n",
    "\n",
    "    Returns:\n",
    "      * float: chi2 probability\n",
    "  \"\"\"\n",
    "\n",
    "  return 1.- stats.chi2.cdf(chi2, ndf)\n",
    "```\n",
    "\n",
    "Enter the code for the $\\chi^2$ probability in the blank line below and check the two results you\n",
    "got above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking the quality of the fits\n",
    "# -> enter code here\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Examination of the non-linear model\n",
    "***\n",
    "\n",
    "For model functions that are non-linear in their parameters, the $\\chi^2$ distribution around the\n",
    "minimum is only approximately a parabola, sometimes it even deviates strongly from it.\n",
    "Whether the deviations are negligible can be checked with the help of profile likelihood and by\n",
    "displaying confidence contours.\n",
    "```\n",
    "from kafe2 import ContoursProfiler\n",
    "\n",
    "# Create contour plot and profiles for the exponential fit\n",
    "cpf = ContoursProfiler(exponential_fit)\n",
    "cpf.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "plt.show()\n",
    "```\n",
    "Enter the code example in the line below to check the fit of the exponential model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking the nonlinear fits\n",
    "# -> enter code here\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Asymmetric parameter uncertainties\n",
    "***\n",
    "\n",
    "If the deviations are large, asymmetric uncertainties must be specified.\n",
    "For this purpose, the option *asymmetric_parameter_errors=True* is set in the *report* function\n",
    "of the fit class.\n",
    "```\n",
    "exponential_fit.report(asymmetric_parameter_errors=True)\n",
    "```\n",
    "It is recommended to document the contours in such cases with strongly asymmetrical parameter\n",
    "uncertainties if more than one parameter is of interest."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# enter code here for output of asymmetric parameters\n",
    "# ->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Influencing the graphical output\n",
    "***\n",
    "\n",
    "The graphical output was not yet optimal in all respects.\n",
    "For example, two data sets were shown in the legend, although there was only the same one for\n",
    "both models.\n",
    "In addition, marker properties and colors can be customized.\n",
    "\n",
    "To influence the graphic *kafe2* provides a method `Plot.customize()`, with whose help for the\n",
    "different graphic elements (*plot_types*: 'data', 'model_line', 'model_error_band', 'ratio',\n",
    "'ratio_error_band') values for *matplotlib* parameters can be specified.\n",
    "\n",
    "The parameters relevant for a *plot_type* and their current values\n",
    "can be displayed using a function of the *Plot* class:\n",
    "```\n",
    "p.get_keywords('model_error_band')\n",
    "```\n",
    "\n",
    "If, as in this example, several fits are contained in one graphic, the parameters are specified\n",
    "as tuples in the form *(index, value)*.\n",
    "\n",
    "The names used for objects and possible values correspond to the names in the configuration file\n",
    "*matplotlibrc* for *matplotlib*.\n",
    "\n",
    "To change the name for the data set and suppress the second output, use the following call:\n",
    "```\n",
    "p.customize('data', 'label', [(0, \"test data\"),(1, '__del__')])\n",
    "```\n",
    "\n",
    "Marker type, size and color of the marker and error bars can also be customized:\n",
    "```\n",
    "# data\n",
    "p.customize('data', 'marker', [(0, 'o'), (1,'o')])\n",
    "p.customize('data', 'markersize', [(0, 5), (1, 5)])\n",
    "p.customize('data', 'color', [(0, 'blue'), (1,'blue')]) # note: although 2nd label is suppressed\n",
    "p.customize('data', 'ecolor', [(0, 'blue'), (1, 'blue')]) # note: although 2nd label is suppressed\n",
    "```\n",
    "\n",
    "The corresponding values for the model function can also be customized:\n",
    "```\n",
    "# model\n",
    "p.customize('model_line', 'color', [(0, 'orange'),(1, 'lightgreen')])\n",
    "p.customize('model_error_band', 'label', [(0, r'$\\pm 1 \\sigma$'),(1, r'$\\pm 1 \\sigma$')])\n",
    "p.customize('model_error_band', 'color', [(0, 'orange'),(1, 'lightgreen')])\n",
    "```\n",
    "\n",
    "It is also possible to change parameters using *matplotlib* functions.\n",
    "To change the size of the axis labels, use the following calls:\n",
    "```\n",
    "# GrÃ¶Ãe der Achsenbeschriftungen\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=20, titlesize=25)\n",
    "```\n",
    "\n",
    "Of course, after these changes the output graphic must be recreated and displayed:\n",
    "```\n",
    "p.plot()\n",
    "plt.show()\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter code to test here:\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Output of fit results as variables\n",
    "***\n",
    "\n",
    "In many applications it is necessary to continue to use the output of a fit in the program code.\n",
    "This is done by the *kafe2* function *Fit.get_result_dict()*, which returns a python dictionary\n",
    "with the fit results.\n",
    "\n",
    "For example:\n",
    "```\n",
    "r = <Fit_object>.get_result_dict()\n",
    "```\n",
    "A formatted output can be obtained with the following line:\n",
    "```\n",
    "print(\"\\n\".join(\"{}\\t{}\".format(k, v) for k, v in result_0.items()))\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test output here\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6 Non-linearity due to uncertainties in *x* - direction\n",
    "***\n",
    "\n",
    "If the errors in x-direction are increased, fitting a straight line also becomes a non-linear\n",
    "problem.\n",
    "To illustrate this, we repeat the same fit as above with increased uncertainties on the x-values:\n",
    "```\n",
    "# the data for this exercise\n",
    "data3 = XYContainer(x_data = x, y_data = y)\n",
    "data3.add_error(axis='x', err_val = 1.0) # was 0.3 before\n",
    "data3.add_error(axis='y', err_val = 0.15, relative = True)\n",
    "\n",
    "# Create 2 Fit objects with the same data but with different model functions\n",
    "linear_fit2 = Fit(data3, model_function=linear_model)\n",
    "\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit2.assign_parameter_latex_names(x='x', a='a', b='b')\n",
    "linear_fit2.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "\n",
    "# Perform the fits.\n",
    "linear_fit2.do_fit()\n",
    "\n",
    "# Optional: Print out a report on the result of each fit.\n",
    "#linear_fit2.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p2 = Plot(fit_objects = linear_fit2)\n",
    "\n",
    "p2.plot(fit_info=True)\n",
    "\n",
    "# Create contour plot and profiles for the linear fit\n",
    "cpf2 = ContoursProfiler(linear_fit2)\n",
    "cpf2.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "\n",
    "# Show the fit results.\n",
    "plt.show()\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter the above code here:\n",
    "# -->\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Little exercise: Adding a square model\n",
    "\n",
    "As a small exercise, another square model, $y(x) = ax^2 + b x + c$, will be added and shown in a\n",
    "plot together with the linear and exponential model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Special features of complex (non-linear) models\n",
    "---\n",
    "\n",
    "Another example of a non-linear fit is a damped oscillation of a thread pendulum.\n",
    "The corresponding measurement data are contained in the following code cell:\n",
    "```\n",
    "# the data\n",
    "t = [ ... ]\n",
    "t_errors = 0.05\n",
    "\n",
    "a = [ ... ]\n",
    "a_errors = 0.05\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the data:\n",
    "t = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0,\n",
    "     10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0, 14.5, 15.0, 15.5, 16.0, 16.5, 17.0, 17.5, 18.0, 18.5, 19.0,\n",
    "     19.5, 20.0, 20.5, 21.0, 21.5,22.0, 22.5, 23.0, 23.5, 24.0, 24.5, 25.0, 25.5, 26.0, 26.5, 27.0, 27.5, 28.0,\n",
    "     28.5, 29.0, 29.5, 30.0, 30.5, 31.0, 31.5, 32.0, 32.5, 33.0, 33.5, 34.0, 34.5, 35.0, 35.5, 36.0, 36.5, 37.0,\n",
    "     37.5, 38.0, 38.5, 39.0, 39.5, 40.0, 40.5, 41.0, 41.5, 42.0, 42.5, 43.0, 43.5, 44.0, 44.5, 45.0, 45.5, 46.0,\n",
    "     46.5, 47.0, 47.5, 48.0, 48.5, 49.0, 49.5, 50.0, 50.5, 51.0, 51.5, 52.0,52.5, 53.0, 53.5, 54.0, 54.5, 55.0,\n",
    "     55.5, 56.0, 56.5, 57.0, 57.5, 58.0, 58.5, 59.0, 59.5, 60.0]\n",
    "t_errors = 0.05\n",
    "\n",
    "a = [ 6.06,  5.17,  3.29,  0.64, -2.26, -4.56, -5.74, -5.58, -4.12, -1.62,\n",
    "      1.11,  3.56,  5.12,  5.43,  4.41,  2.53, -0.18, -2.78, -4.65, -5.5,\n",
    "     -5.04, -3.25, -0.75,  1.79,  3.88,  5.31,  5.2,   3.92,  1.74, -0.85,\n",
    "     -3.13, -4.71, -5.06, -4.26, -2.48, -0.13,  2.19,  4.07,  4.9,   4.64,\n",
    "      3.16,  1.17, -1.54, -3.26, -4.59, -4.64, -3.69, -1.83,  0.38,  2.76,\n",
    "      4.16,  4.58,  4.13,  2.45,  0.28, -1.8,  -3.53, -4.43, -4.31, -3.03,\n",
    "     -1.05,  1.06,  2.79,  3.97,  4.4,   3.37,  1.92, -0.14, -2.29, -3.7,\n",
    "     -4.28, -3.84, -2.44, -0.59,  1.27,  3.11,  3.9,   4.02,  2.85,  1.21,\n",
    "     -0.64, -2.51, -3.41, -3.84, -3.34, -1.75, -0.17,  1.85,  3.23,  3.72,\n",
    "      3.4,   2.54,  0.67, -1.13, -2.8,  -3.77, -3.65, -2.89, -1.43,  0.42,\n",
    "      2.2,   3.26,  3.42,  3.25,  1.88,  0.33, -1.35, -3.02, -3.41, -3.32,\n",
    "     -2.2,  -0.77,  0.92,  2.44,  3.31,  3.44,  2.77,  1.25, -0.13, -1.69, -2.78 ]\n",
    "a_errors = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The amplitude as a function of time is given by the following model function:\n",
    "```\n",
    "# Model function for a pendulum as a one-dimensional, damped harmonic oscillator with zero initial speed\n",
    "# x = time, y_0 = initial_amplitude, l = length of the string,\n",
    "# r = radius of the steel ball, g = gravitational acceleration, c = damping coefficient\n",
    "def damped_harmonic_oscillator(s, a0, l, r, g, c):\n",
    "  l_total = l + r # effective length of the pendulum = length of the string + radius of the steel ball\n",
    "  omega_0 = np.sqrt(g / l_total) # phase speed of an undamped pendulum\n",
    "  omega_d = np.sqrt(omega_0 ** 2 - c ** 2) # phase speed of a damped pendulum\n",
    "  return a0 * np.exp(-c * s) * (np.cos(omega_d * s) + c / omega_d * np.sin(omega_d * s))\n",
    "```\n",
    "\n",
    "Data container and fit object are created as usual:\n",
    "```\n",
    "# create data container\n",
    "data3 = XYContainer(t, a)\n",
    "data3.add_error(axis='x', err_val = t_errors )\n",
    "data3.add_error(axis='y', err_val = a_errors)\n",
    "data3.axis_labels = ('Time t (s)', 'Amplitude A (Â°)')\n",
    "\n",
    "# Create fit object from data and model function\n",
    "fit = Fit(data3, damped_harmonic_oscillator)\n",
    "```\n",
    "\n",
    "The model contains a number of parameters defined by \"auxiliary measurements\".\n",
    "```\n",
    "# Relevant physical magnitudes and their uncertainties\n",
    "lm, delta_lm = 10.000, 0.002     # length of the string, l = 10.0 +- 0.002 m\n",
    "rm, delta_rm = 0.052, 0.001      # radius of the steel ball, r = 0.052 +- 0.001 m\n",
    "#              Note that the uncertainty on y_0 is relative to y_0\n",
    "a0m, delta_a0m = 6.0, 0.01   # amplitude of the steel ball at x=0 in degrees, y_0 = 6 +- 1% degrees\n",
    "```\n",
    "\n",
    "The fit takes this into account by considering the corresponding parameters both as parameters of\n",
    "the fit and as additional data points.\n",
    "In kafe2 such parameters restricted by measurements are considered with the help of the method\n",
    "*Fit.add_parameter_constraint()* and their uncertainties are propagated into the result of the fit:\n",
    "```\n",
    "# Constrain model parameters to measurements\n",
    "fit.add_parameter_constraint(name='l', value=lm, uncertainty=delta_lm)\n",
    "fit.add_parameter_constraint(name='r', value=rm, uncertainty=delta_rm)\n",
    "fit.add_parameter_constraint(name='a0', value=a0m, uncertainty=delta_a0m, relative=True)\n",
    "```\n",
    "\n",
    "Alternatively, you could fix the parameters to fixed values with the method *Fit.fix_parameter()*;\n",
    "however, the uncertainties on the final result of the fit would then have to be calculated using\n",
    "classical error propagation.\n",
    "\n",
    "Another special feature of nonlinear fits is that there are often secondary minima of the cost\n",
    "function - so convergence to the global minimum cannot be guaranteed.\n",
    "It is therefore necessary to select \"reasonable\" start parameters for the fit.\n",
    "This is done using the function *Fit.set_parameter_values()*:\n",
    "```\n",
    "g_initial = 9.81 # initial guess for g\n",
    "c_initial = 0.01 # initial guess for c\n",
    "fit.set_parameter_values(g = g_initial, c = c_initial)\n",
    "\n",
    "fit.set_parameter_values(a0 = a0m, l = lm, r = rm)\n",
    "```\n",
    "\n",
    "If the initial values are completely unknown, values should be tried over a wide range to check\n",
    "that the fits converge to the same minimum.\n",
    "\n",
    "After these preparations, the fit can be made as usual.\n",
    "The following code example also shows how to access the fit results directly if they are to be\n",
    "processed further in the program or if a specific output is to be made.\n",
    "```\n",
    "# Perform the fit\n",
    "fit.do_fit()\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "#fit.report(show_data=False, show_model=False, show_fit_results=True)\n",
    "\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "#fit.report(show_data=False, show_model=False, show_fit_results=True)\n",
    "#    custom printout of results\n",
    "print(\"cost function at minimum: %.4g \" %fit.cost_function_value, \" numer of degrees of freedom:\", fit.ndf)\n",
    "print(\" --> probability: %.1f%%\" %(chi2prob(fit.cost_function_value, fit.ndf)*100) )\n",
    "print(\"parameter names:\\n\", fit.parameter_names)\n",
    "np.set_printoptions(precision=5, suppress=False)\n",
    "print(\"prameter values:\\n\", fit.parameter_values)\n",
    "print(\"parameter uncertainties:\\n\",fit.parameter_errors)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"correlation matrix:\\n\", fit.parameter_cor_mat )\n",
    "\n",
    "# Optional: plot the fit results\n",
    "plot = Plot(fit)\n",
    "plot.plot(fit_info=True)\n",
    "plt.show()\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. Construction of a covariance matrix from individual uncertainties\n",
    "---\n",
    "\n",
    "To be treated:\n",
    "  - dealing with complex uncertainties\n",
    "\n",
    "One of the special strengths of _kafe2_ is the support of correlated uncertainties.\n",
    "This refers to contributions to uncertainties that influence some or all values in the same way -\n",
    "e.g. because they were recorded with the same measuring instrument that has a systematic\n",
    "uncertainty.\n",
    "Often these are common uncertainties of groups of measured values.\n",
    "\n",
    "The following function is used to specify uncertainties\n",
    "> `add_error**([axis], err_val, name=None, correlation=0, relative=False)`\n",
    "  Add an uncertainty source to the data container. Returns an error id which\n",
    "  uniquely identifies the created error source.\n",
    "  **Parameters**\n",
    "  â¢ axis (str or int) â 'x'/0 or 'y'/1\n",
    "  â¢ err_val (float or iterable of float) â pointwise uncertainty/uncertainties for all data points\n",
    "  â¢ name (str or None) â unique name for this uncertainty source. If None, the name\n",
    "    of the error source will be set to a random alphanumeric string.\n",
    "  â¢ correlation (float) â correlation coefficient between any two distinct data points\n",
    "  â¢ relative (bool) â if True, err_val will be interpreted as a relative uncertainty\n",
    "  **Returns** error name\n",
    "  **Return type** str\n",
    "\n",
    "It belongs to the container class, but can also be called via a fit class.\n",
    "With this rather simple interface, independent uncertainties as well as common absolute or\n",
    "relative uncertainties of data points can be specified.\n",
    "The specified uncertainties are converted into a covariance matrix of the data points.\n",
    "If the interface is called several times, the resulting covariance matrices are added together\n",
    "(in accordance with the rules of elementary error propagation).\n",
    "\n",
    "A very simple example will illustrate this.\n",
    "We consider the averaging of four values, which were carried out by two groups with different\n",
    "measuring methods.\n",
    "Each of the two groups gives two measurements;\n",
    "in the first group there is an absolute uncertainty common to the two measurements;\n",
    "the second group indicates a relative uncertainty correlated between its two measurements, e.g.\n",
    "caused by a scaling error.\n",
    "Furthermore, the measurements are based on a common (theoretical) assumption which leads to an\n",
    "absolute uncertainty common to all measurements.\n",
    "\n",
    "For this simple problem we use the simplest data structure of *kafe2*, the _IndexedContainer_, to\n",
    "provide the data:\n",
    "```\n",
    "from kafe2 import IndexedContainer\n",
    "idx_data = IndexedContainer([5.3, 5.2, 4.7, 4.8])\n",
    "```\n",
    "As model we choose a constant function:\n",
    "```\n",
    "# the very simple \"model\"\n",
    "def average (a):\n",
    "  return a\n",
    "```\n",
    "\n",
    "The uncertainties are then stated as follows\n",
    "                (Note: In this case, the _axis_ parameter is not required!):\n",
    "  1. each measurement has its own independent uncertainty\n",
    "   `err_stat = idx_data.add_error([.2, .2, .2, .2])`\n",
    "  2. the uncertainty common to the first two values\n",
    "   `err_syst12 = idx_data.add_error([.175, .175, 0., 0.], correlation = 1.)`\n",
    "  3. the relative uncertainty common to the last two values\n",
    "   `err_syst34 = idx_data.add_error([0., 0., .05, 0.05], correlation = 1., relative=True)`\n",
    "  4. the uncertainty common to all values\n",
    "   `err_syst = idx_data.add_error(0.15, correlation = 1.)`\n",
    "\n",
    "We should also provide suitable labels for the data:\n",
    "```\n",
    "# Assign labels\n",
    "idx_data.label = 'Test data'\n",
    "idx_data.axis_labels = [None,'Measured value (a.o.)']\n",
    "```\n",
    "The execution of the fit is well known by now:\n",
    "```\n",
    "# set up the fit\n",
    "ifit = Fit(idx_data, average)\n",
    "ifit.model_label = 'average value'\n",
    "\n",
    "# perform the fit#\n",
    "ifit.do_fit()\n",
    "```\n",
    "The results can of course be obtained with the _report()_ function, if necessary also as a\n",
    "graphical representation:\n",
    "```\n",
    "# report results\n",
    "ifit.report()\n",
    "p=Plot(ifit)\n",
    "p.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The labeling of the x-axis is not yet appropriate - only the indices of the measurements should\n",
    "appear here.\n",
    "With a little help from *matplotlib* this can be achieved.\n",
    "To do so, you have to access the *axis* object of the generated figure and make the appropriate\n",
    "adjustments.\n",
    "To do this, insert the following code after the line *p.plot()* before *plt.show()*:\n",
    "```\n",
    "# illustrate some a-posteriory fixes to plot layout by accessing the axis object\n",
    "_ax = p.axes[0]['main']\n",
    "_ax.set_xticks(range(4)) # Integer axis ticks\n",
    "```\n",
    "\n",
    "If a problem contains several contributions to the overall uncertainty, one would usually like to\n",
    "study the influence of individual components.\n",
    "For this purpose, one can comfortably work with the functions *disable_error()* and\n",
    "*enable_error()* and make appropriate fits:\n",
    "```\n",
    "print(\"disabling common sysytematic error\")\n",
    "idx_data.disable_error(err_syst)\n",
    "_ifit = Fit(idx_data, average)\n",
    "_ifit.do_fit()\n",
    "_ifit.report()\n",
    "#      do not forget to switch on again\n",
    "idx_data.enable_error(err_syst)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "# -->\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. Application from the real world: Fit of a Breit-Wigner resonance\n",
    "---\n",
    "\n",
    "To be treated:\n",
    "  - dealing with complex uncertainties\n",
    "  - the creation of an appealing graphical output\n",
    "  - studying the influence of individual error components\n",
    "\n",
    "Typically, the uncertainties of the measurement data are much more complex than in the examples\n",
    "discussed so far.\n",
    "In most cases there are uncertainties in ordinate and abscissa, and in addition to the\n",
    "independent uncertainties of each data point there are common, correlated uncertainties for all\n",
    "of them.\n",
    "\n",
    "With the method *add_error()* or *add_matrix_error()* uncertainties can be specified on the 'x'\n",
    "and 'y' data, either in the form of independent or correlated, relative or absolute uncertainties\n",
    "of all or groups of measured values or by specifying the complete covariance or correlation matrix.\n",
    "All uncertainties specified in this way are included in the global covariance matrix for the fit.\n",
    "\n",
    "As an example, we consider measurements of a cross section as a function of the energy near a\n",
    "resonance.\n",
    "These are combined measurement data from the four experiments at CERN's LEP accelerator, which\n",
    "were corrected for effects caused by photon radiation:\n",
    "\n",
    "Measurements of the hadronic cross section $\\sigma_{e^+e^- \\to {\\rm hadrons}}$ as a function of\n",
    "the centre-of-mass energy $E_{CM}$.\n",
    "```\n",
    "## Data:\n",
    "# Center-of-mass energy E (GeV)\n",
    "E = [ 88.387, 89.437, 90.223, 91.238, 92.059, 93.004, 93.916 ]\n",
    "E_errors = [ 0.005, 0.0015, 0.005, 0.003, 0.005, 0.0015, 0.005 ]\n",
    "ECor_abs = 0.0017  # correlated absolute errors\n",
    "\n",
    "# hadronic cross section with photonic corrections applied (nb)\n",
    "sig = [6.803, 13.965, 26.113, 41.364, 27.535, 13.362, 7.302 ]\n",
    "sig_errors = [ 0.036, 0.013, 0.075, 0.010, 0.088, 0.015, 0.045 ]\n",
    "sigCor_rel = 0.0007\n",
    "```\n",
    "\n",
    "As a model we use a modified Breit-Wigner resonance with a width dependent on the centre-of-mass\n",
    "energy (\"$s$-dependent width\", where $s = E_{CM}^2$):\n",
    "```\n",
    "## Model:\n",
    "# Breit-Wigner with s-dependent width\n",
    "def BreitWigner(E, s0 = 41.0, M = 91.2, G = 2.5):\n",
    "    s = E*E\n",
    "    Msq = M*M\n",
    "    Gsq = G*G\n",
    "    return s0*s*Gsq/((s-Msq)*(s-Msq)+(s*s*Gsq/Msq))\n",
    "```\n",
    "\n",
    "The data container with the uncertainties is created as follows:\n",
    "```\n",
    "BWdata= XYContainer(ECM, sig)\n",
    "# add independent errors\n",
    "error_name_sig = BWdata.add_error(axis='x', name = 'deltaE', err_val = E_errors )\n",
    "error_name_E = BWdata.add_error(axis='y', name = 'deltaSig', err_val = sig_errors )\n",
    "# add fully correlated, absolute Energy errors\n",
    "error_name_ECor = BWdata.add_error(axis='x', name='Ecor',err_val = ECor_abs, correlation = 1.)\n",
    "# add fully correlated, relative cross section errors\n",
    "error_name_sigCor = BWdata.add_error(axis='y', name='sigCor',\n",
    "                            err_val = sigCor_rel, correlation = 1., relative=True)\n",
    "```\n",
    "\n",
    "Whether the uncertainties are independent or correlated is determined by the parameter\n",
    "*correlation*;\n",
    "for independent uncertainties it is zero, for uncertainties common to all data entries it is one.\n",
    "Values between 0. and 1. are also allowed;\n",
    "however, in practice the covariance matrix for describing the overall uncertainty is usually\n",
    "composed of uncorrelated and fully correlated components.\n",
    "The names given in the *add_error* function allow the individual error components to be accessed\n",
    "later.\n",
    "\n",
    "Fit and result output follow the usual procedure:\n",
    "```\n",
    "BWfit = Fit(BWdata, BreitWigner)\n",
    "BWfit.do_fit()\n",
    "BWfit.report()\n",
    "# Optional: plot the fit results\n",
    "BWplot = Plot(BWfit)\n",
    "BWplot.plot(fit_info=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Enhancement of the graphical output**\n",
    "\n",
    "To ensure that the type of data is clearly described, suitable names should be assigned.\n",
    "The lines below must be inserted before the *Fit* object is created.\n",
    "```\n",
    "BWdata.label = 'QED-corrected hadronic cross-sections'\n",
    "BWdata.axis_labels = ('CM Energy (GeV)', '$\\sigma_h$ (nb)' )\n",
    "```\n",
    "\n",
    "A suitable name for the model should also be set in the legend for the graphical output.\n",
    "To do this, insert the line below after the *Fit* object has been created:\n",
    "```\n",
    "BWfit.model_label = 'Beit-Wigner with s-dependent width'\n",
    "```\n",
    "\n",
    "If a nicely set expression for the model function is desired, LaTeX names can be set for the\n",
    "model, the parameters and the model function:\n",
    "```\n",
    "# set LaTeX names for printout in info-box\n",
    "BWfit.assign_parameter_latex_names(E='E', s0=r'{\\sigma^0}', M=r'{M_Z}', G=r'{\\Gamma_Z}')\n",
    "BWfit.assign_model_function_latex_name(r'\\sigma^{\\rm ew}_{e^+e^-\\to{\\rm hadrons}}')\n",
    "BWfit.assign_model_function_latex_expression(\n",
    "               r'{s0}\\frac{{ {E}^2{G}^2}}{{({E}^2-{M}^2)^2+({E}^4{G}^2/{M}^2)}}')\n",
    "```\n",
    "Note: The doubling of the brackets \"{\" and \"}\" is necessary because in *kafe2*, similar to the\n",
    "Python *format* function, they are also used to pass parameters.\n",
    "\n",
    "A more appropriate name for the band to indicate the model uncertainty is desirable.\n",
    "To do this, insert the following line after the *Plot* object has been created:\n",
    "```\n",
    "BWplot.customize('model_error_band', 'label', [r'$\\pm 1\\sigma$'])\n",
    "```\n",
    "In this example, however, the model uncertainty is extremely small (well below 0.1%) and\n",
    "therefore not visible in the graph.\n",
    "You can suppress the output in the legend with the following specification:\n",
    "```\n",
    "BWplot.customize('model_error_band', 'label', ['__del__'])\n",
    "```\n",
    "Sometimes the uncertainty band is covered by the line;\n",
    "in such cases a dashed or dotted line should be used for the model:\n",
    "```\n",
    "BWplot.customize('model_line', 'linestyle', ['--'])\n",
    "```\n",
    "\n",
    "Now the edges of the plot area should be adjusted to achieve a good aesthetic impression.\n",
    "This is done by directly accessing the *axis* object and using *matplotlib* methods.\n",
    "The lines below are inserted before *plt.show()*:\n",
    "```\n",
    "# illustrate some a-posteriory fixes to plot layout by accessing the axis object\n",
    "def scale_plot_range(lims, sf):\n",
    "   d = 0.5*(sf-1.)*(lims[1]-lims[0])\n",
    "   return [lims[0]-d, lims[1]+d]\n",
    "_ax = BWplot.axes[0]['main']\n",
    "_ax.set_xlim(scale_plot_range(_ax.get_xlim(), 1.1))\n",
    "_ax.set_ylim(scale_plot_range(_ax.get_ylim(), 1.1))\n",
    "\n",
    "```\n",
    "Since this is a nonlinear fit, profile likelihood and confidence contours should still be displayed.\n",
    "The following line must be inserted before *plt.show()*:\n",
    "```\n",
    "ContoursProfiler(BWfit).plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "```\n",
    "!!! Patience: the calculation of the contours is computationally complex and takes a certain\n",
    "amount of time!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' the data for the Breit-Wigner example'''\n",
    "# Center-of-mass energies E (GeV)\n",
    "ECM = [ 88.387, 89.437, 90.223, 91.238, 92.059, 93.004, 93.916 ]\n",
    "E_errors = [ 0.005, 0.0015, 0.005, 0.003, 0.005, 0.0015, 0.005 ]\n",
    "ECor_abs = 0.0017  # correlated absolute errors\n",
    "\n",
    "# hadronic cross sections with photonic corrections applied (nb)\n",
    "sig = [6.803, 13.965, 26.113, 41.364, 27.535, 13.362, 7.302 ]\n",
    "sig_errors = [ 0.036, 0.013, 0.075, 0.010, 0.088, 0.015, 0.045 ]\n",
    "sigCor_rel = 0.0007\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# enter the code from above here\n",
    "# -->\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Study of the influence of individual error components**\n",
    "To investigate the influence of individual error components on the result, individual sources of\n",
    "uncertainty can be switched off with the method *disable_error()* and a new fit can be performed,\n",
    "shown here for the correlated uncertainty of the center-of-mass energies:\n",
    "```\n",
    "print('!!!  disabling error component ', error_name_ECor)\n",
    "BWfit.disable_error(error_name_ECor)\n",
    "BWfit.do_fit()\n",
    "BWfit.report(show_data=False, show_model=False)\n",
    "\n",
    "# do not forget to switch on again !\n",
    "print('!!!  re-enabling error component ', error_name_ECor)\n",
    "BWfit.enable_error(error_name_ECor)\n",
    "\n",
    "#### fallback option with new fit object\n",
    "#print('!!!  disabling error component ', error_name_ECor)\n",
    "#BWdata.disable_error(error_name_ECor)\n",
    "#_fit = Fit(BWdata, BreitWigner)\n",
    "#_fit.do_fit()\n",
    "#_fit.report(show_data=False, show_model=False)\n",
    "#BWdata.enable_error(error_name_ECor)\n",
    "```\n",
    "The result is almost identical to the previous one, only the uncertainty of the mass is now smaller.\n",
    "This was also to be expected, because a correlated change of all energies should not influence\n",
    "the width or height of the resonance.\n",
    "\n",
    "With the method `enable_error(error_name_ECor)` the uncertainty source is reactivated.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# try it out here\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 6. Fit to histogram data\n",
    "***\n",
    "\n",
    "In principle, the fit of a distribution density to a frequency distribution can also be\n",
    "understood as a functional fit.\n",
    "However, there are some special features that must be taken into account:\n",
    "\n",
    "- The function value for a bin corresponding to the value of a distribution density (PDF=Particle\n",
    "  Density Function) corresponds to the integral of the PDF via the bin\n",
    "- The uncertainty of a bin entry results from the Poisson distribution, which can only be\n",
    "  approximated by a Gaussian distribution for very large numbers of entries per bin.\n",
    "\n",
    "Therefore *kafe2* offers a special method to fit a distribution density to histograms, the\n",
    "classes *HistContainer* to store the histogram data and *HistFit* to perform the fit:\n",
    "```\n",
    "from kafe2 import HistContainer, HistFit\n",
    "```\n",
    "\n",
    "Twice the negative logarithm of the Poisson likelihood is used as the cost function to evaluate\n",
    "the agreement of the adjusted PDF with the bin entries in the frequency distribution, other\n",
    "options are configurable.\n",
    "\n",
    "In this simple example, we use the frequency distribution of Gaussian-distributed random numbers\n",
    "to which a Gaussian distribution is fitted.\n",
    "```\n",
    "def normal_distribution_pdf(x, mu, sigma):\n",
    "  return np.exp(-0.5 * ((x - mu) / sigma) ** 2) / np.sqrt(2.0 * np.pi * sigma** 2)\n",
    "```\n",
    "\n",
    "The data is generated randomly from the standard normal distribution:\n",
    "```\n",
    "# create a random dataset of 100 random values,\n",
    "#  following a standard normal distribution with mu=0 and sigma=1\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "```\n",
    "\n",
    "The data container and the fit object are created in the same way as in the previous examples:\n",
    "```\n",
    "# Create a histogram from the dataset by specifying the bin range and the number of bins.\n",
    "# Alternatively the bin edges can be set.\n",
    "histogram = HistContainer(n_bins=10, bin_range=(-5, 5), fill_data=data)\n",
    "\n",
    "# create the Fit object by specifying a density function\n",
    "fit = HistFit(data=histogram, model_density_function=normal_distribution_pdf)\n",
    "```\n",
    "\n",
    "Carrying out the fit and outputting the results are no different from the procedure used in the\n",
    "previous examples:\n",
    "```\n",
    "# do the fit\n",
    "fit.do_fit()\n",
    "\n",
    "# Optional: print a report to the terminal\n",
    "fit.report()\n",
    "\n",
    "# Optional: create a plot and show it\n",
    "phist = Plot(fit)\n",
    "phist.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "At this point we should take another look at the possibilities for customizing the graphical output.\n",
    "The plot adapter for histograms knows the values *data*, *model* and *model_density* as *plot_type*.\n",
    "By calling `print(phist.get_keywords(<plot_type>))` the adjustable parameters can be retrieved.\n",
    "Here is a suggestion for code to customize the graphic output, which must be placed before the\n",
    "*phist.plot()* command:\n",
    "```\n",
    "## reprise: plot customization\n",
    "#    data\n",
    "phist.customize('data', 'label', [\"random Gaussian data\"] )\n",
    "phist.customize('data', 'marker', ['o'])\n",
    "phist.customize('data', 'markersize', [5])\n",
    "phist.customize('data', 'color', ['blue'])\n",
    "phist.customize('data', 'ecolor', ['blue'])\n",
    "#    model\n",
    "phist.customize('model_density', 'label', [\"Gaussian PDF\"])\n",
    "phist.customize('model_density', 'color', [\"black\"])\n",
    "phist.customize('model', 'label', [\"entries per bin\"])\n",
    "phist.customize('model', 'facecolor', [\"lightgrey\"])\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# try here\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 7. Likelihood fits\n",
    "***\n",
    "\n",
    "If only few measurements are available, it is not possible to obtain a meaningful frequency\n",
    "distribution, because a coarse division into bins would distort the measurements, while a too\n",
    "fine division would lead to bins with very few or even zero entries.\n",
    "The method already used above for fitting a distribution density to a frequency distribution is\n",
    "then not applicable.\n",
    "In such cases, a direct fit to the unbinned data using the maximum likelihood method is used.\n",
    "Also this procedure is implemented in *kafe2*.\n",
    "Only the appropriate classes must be imported:\n",
    "```\n",
    "from kafe2.fit import UnbinnedContainer, UnbinnedFit\n",
    "```\n",
    "\n",
    "In this example, we use 160 individual measurements of the lifetime of muons from cosmic\n",
    "radiation stopped in a detector to illustrate this.\n",
    "The frequency distribution is an exponential distribution over flat ground:\n",
    "\n",
    "```\n",
    "def pdf(t, tau=2.2, fbg=0.1, a=1., b=9.75):\n",
    "  \"\"\"\n",
    "  Probability density function for the decay time of a myon.\n",
    "  The pdf is normalized to an integral of one for the interval (a, b).\n",
    "  :param t: decay time\n",
    "  :param fbg: background\n",
    "  :param tau: expected mean of the decay time\n",
    "  :param a: the minimum decay time which can be measured\n",
    "  :param b: the maximum decay time which can be measured\n",
    "  :return: probability for decay time x\n",
    "  \"\"\"\n",
    "  pdf1 = np.exp(-t / tau) / tau / (np.exp(-a / tau) - np.exp(-b / tau))\n",
    "  pdf2 = 1. / (b - a)\n",
    "  return (1 - fbg) * pdf1 + fbg * pdf2\n",
    "```\n",
    "\n",
    "Please note that the frequency distribution for all possible parameter values must be normalized\n",
    "to one!\n",
    "\n",
    "There is only one small particularity regarding the fit procedure:\n",
    "due to the small number of observations, the background portion is subject to a large uncertainty\n",
    "and can therefore even become negative during the parameter variation in the progression of the\n",
    "fitting algorithm.\n",
    "To avoid this \"unphysical\" range of the parameter, there is the option\n",
    "`fit.limit_parameter(<name>, lower=<min>, upper=<max>)`.\n",
    "\n",
    "All further steps in the following sample code are already known:\n",
    "```\n",
    "data = UnbinnedContainer(dT) # create the kafe data object\n",
    "data.label = 'lifetime measurements'\n",
    "data.axis_labels = ('Myon Life Time ' r'$\\tau$' ' (Âµs)','Density' )\n",
    "\n",
    "# create the fit object and set the pdf for the fit\n",
    "LLfit = UnbinnedFit(data=data, model_density_function = pdf)\n",
    "\n",
    "# assign latex names for model and parameters for nicer display\n",
    "LLfit.model_label = 'Exponential decay + flat background'\n",
    "LLfit.assign_parameter_latex_names(t='t', tau=r'\\tau', fbg='f', a='a', b='b')\n",
    "LLfit.assign_model_function_latex_expression(\"\\\\frac{{ (1-{fbg}) \\, e^{{-{0}/{tau}}}}}\"\n",
    "    \"{{{tau}(e^{{-{a}/{tau}}}-e^{{-{b}/{tau}}})}} + \\\\frac{{ {fbg} }} {{ {b}-{a} }}\")\n",
    "\n",
    "# Fix the parameters a and b ...\n",
    "a = 1.0\n",
    "b = 11.5\n",
    "LLfit.fix_parameter(\"a\", a)\n",
    "LLfit.fix_parameter(\"b\", b)\n",
    "# ... and limit parameter fbg\n",
    "LLfit.limit_parameter(\"fbg\", lower=0., upper=1.)\n",
    "\n",
    "LLfit.do_fit()  # perform the fit\n",
    "LLfit.report(asymmetric_parameter_errors=True)\n",
    "\n",
    "pLL = Plot(LLfit)  # create a plot object\n",
    "pLL.x_range = [a, b]\n",
    "pLL.plot(fit_info=True, asymmetric_parameter_errors=True)  # plot the data and the fit\n",
    "#pLL.axes[0]['main'].set_xlabel('Life time '+r'$\\tau$'+' (Âµs)', size='large')  # overwrite the x-axis label\n",
    "\n",
    "cpfLL = ContoursProfiler(LLfit, profile_subtract_min=False)  # Optional: create a contours profile\n",
    "cpfLL.plot_profiles_contours_matrix(parameters=['tau', 'fbg'])  # Optional: plot the contour matrix for tau and fbg\n",
    "\n",
    "plt.show()  # show the plot(s)\n",
    "```\n",
    "\n",
    "Interesting is the special form of graphical representation of the data, where in this case each\n",
    "measured value is represented by a line.\n",
    "The density of the lines per unit length corresponds to the distribution density."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' the data for the myon life time example'''\n",
    "# real data from measurement with a Water Cherenkov detector (\"Kamiokanne\")\n",
    "dT = [7.42, 3.773, 5.968, 4.924,  1.468,  4.664,  1.745,  2.144,  3.836,  3.132,\n",
    "  1.568,  2.352,  2.132,  9.381,  1.484,  1.181,  5.004,  3.06,   4.582,  2.076,\n",
    "  1.88,   1.337,  3.092,  2.265,  1.208,  2.753,  4.457,  3.499,  8.192,  5.101,\n",
    "  1.572,  5.152,  4.181,  3.52,   1.344, 10.29,   1.152,  2.348,  2.228,  2.172,\n",
    "  7.448,  1.108,  4.344,  2.042,  5.088,  1.02,   1.051,  1.987,  1.935,  3.773,\n",
    "  4.092,  1.628,  1.688,  4.502,  4.687,  6.755,  2.56,   1.208,  2.649,  1.012,\n",
    "  1.73,   2.164,  1.728,  4.646,  2.916,  1.101,  2.54,   1.02,   1.176,  4.716,\n",
    "  9.671,  1.692,  9.292, 10.72,   2.164,  2.084,  2.616,  1.584,  5.236,  3.663,\n",
    "  3.624,  1.051,  1.544,  1.496,  1.883,  1.92,   5.968,  5.89,   2.896,  2.76,\n",
    "  1.475,  2.644,  3.6,    5.324,  8.361,  3.052,  7.703,  3.83,   1.444,  1.343,\n",
    "  4.736,  8.7,    6.192,  5.796,  1.4,    3.392,  7.808,  6.344,  1.884,  2.332,\n",
    "  1.76,   4.344,  2.988,  7.44,   5.804,  9.5,    9.904,  3.196,  3.012,  6.056,\n",
    "  6.328,  9.064,  3.068,  9.352,  1.936,  1.08,   1.984,  1.792,  9.384, 10.15,\n",
    "  4.756,  1.52,   3.912,  1.712, 10.57,   5.304,  2.968,  9.632,  7.116, 1.212,\n",
    "  8.532,  3.000,  4.792,  2.512,  1.352,  2.168,  4.344,  1.316,  1.468, 1.152,\n",
    "  6.024,  3.272,  4.96,  10.16,   2.14,   2.856, 10.01,   1.232, 2.668, 9.176 ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# try the likelihood fit here\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## 8. Multi-Fits:\n",
    "### simultaneous fit of model functions to different data sets\n",
    "***\n",
    "Very often the models are too complex to determine all parameters in a fit to a single model, but\n",
    "model parameters are themselves results of model fits, or the same parameter occurs in different\n",
    "measurement series.\n",
    "\n",
    "For such cases *kafe2* offers the possibility to perform several fits of different models with\n",
    "common parameters to different data sets.\n",
    "\n",
    "For this purpose, the *MultiFit* package must also be imported:\n",
    "```\n",
    "from kafe2 import MultiFit\n",
    "```\n",
    "\n",
    "As a simple example, we consider the determination of an ohmic resistance at room temperature,\n",
    "which heats up at higher current flow and thus changes its resistance according to its\n",
    "temperature coefficient.\n",
    "Therefore, in addition to the current through the resistor, the temperature is measured for each\n",
    "given voltage value.\n",
    "Triplets of measured values must therefore be evaluated.\n",
    "\n",
    "The temperature dependence is described empirically by a simple quadratic model:\n",
    "```\n",
    "# empirical model for T(U): a parabola\n",
    "def empirical_T_U_model(U, p2=1.0, p1=1.0, p0=0.0):\n",
    "    # use quadratic model as empirical temperature dependence T(U)\n",
    "    return p2 * U**2 + p1 * U + p0\n",
    "```\n",
    "\n",
    "The resistance as a function of temperature is given by the temperature coefficient $\\alpha$ and\n",
    "is modeled as follows\n",
    "```\n",
    "# model of current-voltage dependence I(U) for a heating resistor\n",
    "def I_U_model(U, R0=1., alph=0.004, p2=1.0, p1=1.0, p0=0.0):\n",
    "    # use quadratic model as empirical temperature dependence T(U)\n",
    "    t_ref = 0.\n",
    "    _delta_t = empirical_T_U_model(U, p2, p1, p0) - t_ref\n",
    "    # plug the temperature into the model\n",
    "    return U / (R0 * (1.0 + _delta_t * alph))\n",
    "```\n",
    "\n",
    "So in this case the model for resistance contains the first model for the dependence of\n",
    "temperature on the current determined by the applied voltage.\n",
    "\n",
    "Here is the data for this example:\n",
    "```\n",
    "# the data\n",
    "U = [ 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5,\n",
    "      6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0 ]\n",
    "I = [ 0.5,  0.89, 1.41, 1.67, 2.3,  2.59, 2.77, 3.57, 3.94,  4.24, 4.73,\n",
    "      4.87, 5.35, 5.74, 5.77, 6.17, 6.32, 6.83, 6.87, 7.17 ]\n",
    "T = [ 20.35, 20.65, 22.25, 23.65, 26.25, 27.85, 29.85, 34.25, 37.75, 41.95,\n",
    "     44.85, 50.05, 54.25, 60.55, 65.05, 69.95, 76.85, 81.55, 85.45, 94.75 ]\n",
    "sigU, sigI, sigT = 0.2, 0.1, 0.5 # uncertainties\n",
    "```\n",
    "\n",
    "The Fit procedure is hardly different from the procedure presented so far.\n",
    "First, the data containers and fits for the two models are defined as:\n",
    "```\n",
    "# Step 1: construct the singular data containers and fit objects\n",
    "TU_data = XYContainer(U,T)\n",
    "TU_data.label = 'Temperaturen'\n",
    "TU_data.axis_labels = ['Spannung (V)','Temperatur (Â°C)']\n",
    "fit_1 = Fit(TU_data, model_function=empirical_T_U_model)\n",
    "fit_1.model_label = 'Parametrisierung'\n",
    "\n",
    "IU_data = XYContainer(U,I)\n",
    "IU_data.label = 'StrÃ¶me'\n",
    "IU_data.axis_labels = ['Spannung (V)','Strom (A)']\n",
    "fit_2 = Fit(IU_data, model_function=I_U_model)\n",
    "fit_2.model_label = 'TeperaturabhÃ¤ngiger Leitwert'\n",
    "\n",
    "```\n",
    "\n",
    "Then both fits are combined to a *MultiFit*.\n",
    "```\n",
    "# Step 2: construct a MultiFit object\n",
    "multi_fit = MultiFit(fit_list=[fit_1, fit_2], minimizer='iminuit')\n",
    "```\n",
    "Only now are the uncertainties added - this time to the fit objects.\n",
    "This also allows the uncertainties on the x-axis, which are common to both data sets, to be taken\n",
    "into account.\n",
    "```\n",
    "# Step 3: Add errors (to the fit object in this case)\n",
    "multi_fit.add_error(sigT, 0, axis='y')  # declare errors on T\n",
    "multi_fit.add_error(sigI, 1, axis='y')  # declare errors on I\n",
    "multi_fit.add_error(sigU, 'all', axis='x') # shared error on x axis\n",
    "```\n",
    "\n",
    "The next step is to define meaningful names for the output:\n",
    "```\n",
    "# (Optional): assign names for models and parameters\n",
    "multi_fit.assign_parameter_latex_names(\n",
    "    U='U', p2='p_2', p1='p_1', p0='p_0', R0='R_0', alph=r'\\alpha_\\mathrm{T}')\n",
    "multi_fit.assign_model_function_expression('{p2}*{U}^2 + {p1}*{U} + {p0}', fit_index=0)\n",
    "multi_fit.assign_model_function_latex_expression(r'{p2}\\,{U}^2 + {p1}\\,{U} + {p0}', fit_index=0)\n",
    "multi_fit.assign_model_function_expression('{U} / ({R0} * (1 + ({p2}*{U}^2 + {p1}*{U} + {p0}) * {alph}))', fit_index=1)\n",
    "multi_fit.assign_model_function_latex_expression(r'\\frac{{{U}}}{{{R0} \\cdot (1 + ({p2}{U}^2 + {p1}{U} + {p0}) \\cdot {alph})}}', fit_index=1)\n",
    "```\n",
    "\n",
    "The rest then runs exactly as often shown:\n",
    "```\n",
    "# Step 4: do the fit\n",
    "multi_fit.do_fit()\n",
    "\n",
    "# (Optional): print the results\n",
    "multi_fit.report()\n",
    "\n",
    "# (Optional): plot the results\n",
    "plot = Plot(multi_fit, separate_figures=True)\n",
    "plot.customize('data', 'marker', ['.','.'])\n",
    "plot.customize('data', 'markersize', [6,6])\n",
    "\n",
    "plot.customize('model_error_band', 'label', [(0, r'$\\pm 1\\sigma$'),(1, r'$\\pm 1\\sigma$')])\n",
    "plot.plot()\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "For the graphical representation, an adapted entry was made in the legend for the uncertainty\n",
    "band using the *customize* method already discussed.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# enter own code here\n",
    "# -->\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}