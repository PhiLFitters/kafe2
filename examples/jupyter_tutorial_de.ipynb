{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# jupyter notebook Tutorial:   \n",
    "#    Anpassung von Modellen an Daten mit *kafe2* \n",
    "\n",
    "                                                Günter Quast, April 2020\n",
    "---\n",
    "## Grundsätzliches zu Jupyter Notebooks\n",
    "\n",
    "Diese Datei vom Typ `.ipynb` enthält ein Tutorial als `jupyter notebook`.\n",
    "`jupyter` bietet eine Browser-Schnittstelle mit einer (einfachen) Entwicklungsumgebung für\n",
    "`python`-Code und erklärende Texte im intuitiven *markdown*-Format.\n",
    "Die Eingabe von Formeln im `LaTeX`-Format wird ebenfalls unterstützt.\n",
    "\n",
    "Eine Zusammenstellung der wichtigsten Befehle zur Verwendung von *jupyter* als Arbeitsumgebung\n",
    "findet sich im Notebook\n",
    "[*JupyterCheatsheet.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/JupyterCheatsheet.ipynb).\n",
    "Grundlagen zur statistischen Datenauswertung finden sich in den Notebooks \n",
    "[*IntroStatistik.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/IntroStatistik.ipynb)\n",
    "und\n",
    "[*Fehlerrechnung.ipynb*](https://git.scc.kit.edu/yh5078/datenanalyse/-/blob/master/jupyter/Fehlerrechnung.ipynb).\n",
    "\n",
    "In *jupyter* werden Code und Text in jeweils einzelne Zellen eingegeben. \n",
    "Aktive Zellen werden durch einen blauen Balken am Rand angezeigt.\n",
    "Sie können sich in zwei Zuständen befinden: im Edit-Mode ist das Eingabefeld weiß, im\n",
    "Command-Mode ist es ausgegraut.\n",
    "Durch Klicken in den Randbereich wird der Command-Modus gewählt, ein Klick in das Textfeld einer\n",
    "Code-Zelle schaltet in den Edit-Mode.\n",
    "Die Taste `esc` kann ebenfalls verwendet werden, um den Edit-Modus zu verlassen.\n",
    "\n",
    "Die Eingabe von `a` im Command-Mode erzeugt eine neue leere Zelle oberhalb der aktiven Zelle, `b`\n",
    "eine unterhalb. Eingabe von `dd` löscht die betreffende Zelle.\n",
    "\n",
    "Zellen können entweder den Typ `Markdown` oder `Code` haben.\n",
    "Die Eingabe von `m` im Command-Modus setzt den Typ Markdown, Eingabe von `y` wählt den Typ Code.\n",
    "\n",
    "Prozessiert - also Text gesetzt oder Code ausgeführt - wird der Zelleninhalt durch Eingabe von\n",
    "`shift+return`, oder auch `alt+return` wenn zusätzlich eine neue, leere Zelle erzeugt werden soll.\n",
    "\n",
    "Die hier genannten Einstellungen sowie das Einfügen, Löschen oder Ausführen von Zellen können\n",
    "auch über das PullDown-Menü am oberen Rand ausgeführt werden.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übersicht: *kafe*2\n",
    "***\n",
    "\n",
    "\n",
    "*kafe*2 ist ist eine erweiterte Version des seit 2012 entwickelten Pakets *kafe* zur Anpassung\n",
    "von Modellfunktionen an Daten.\n",
    "\n",
    "Unterstützt werden verschiedene Datentypen wie einfache indizierte Daten, zweidimensionale\n",
    "Datenpunkte (eine Größe *\"x\"* und eine abhängige Größe *\"y\"*) sowie Häufigkeitsverteilungen\n",
    "(Histogramme).\n",
    "Unsicherheiten sowohl der abhängigen wie auch der unabhängigen Größen und gegebenenfalls deren\n",
    "Korrelationen werden unterstützt.\n",
    "Dazu wird aus verschiedenen Arten von spezifizierten Unsicherheiten die globale Kovarianzmatrix\n",
    "erstellt und in der Anpassung berücksichtigt.\n",
    "Im  Vergleich zu vielen anderen Anpassungswerkzeugen ist diese Möglichkeit ein\n",
    "Alleinstellungsmerkmal von  *kafe(2)*.\n",
    "\n",
    "Unterstützt wird auch die gleichzeitige Anpassung mehrerer Modelle mit jeweils eigenen und\n",
    "zusätzlich allen oder mehreren Modellen gemeinsamen Parametern an verschiedene Datensätze\n",
    "(\"Multi-Fit\").\n",
    "\n",
    "Zur Minimierung des Abstandsmaßes zwischen Daten und Modellfunktion(en) werden numerische\n",
    "Verfahren angewandt, die aus der quelloffenen, *python*-basierten Softwareumgebung *scipy* oder\n",
    "dem am CERN entwickelten Paket *MINUIT* stammen.\n",
    "Das jeweils minimierte Abstandsmaß (oder auch die \"Kostenfunktion\") entspricht dem mit einem\n",
    "Faktor Zwei multiplizierten negativen natürliche Logarithmus der Likelihood-Funktion\n",
    "$-2\\,\\ln{\\cal L}$ der Daten für das gegebene Modell.\n",
    "Für Gauß-förmige Unsicherheiten der Datenpunkte entspricht dies der Methode der kleinsten\n",
    "Quadrate (auch \"$\\chi^2$-Methode\").\n",
    "Andere, auf dem Likelihood-Prinzip beruhende Kostenfunktionen für die Anpassung von\n",
    "Wahrscheinlichkeitsdichten an Histogramme oder an indizierte Daten sind ebenfalls verfügbar.\n",
    "\n",
    "Zur Bestimmung der Unsicherheiten auf die Parameter des angepassten Modells wird die Methode der\n",
    "Profil-Likelihood bereit gestellt, mit deren Hilfe Konfidenzintervalle für die einzelnen\n",
    "Parameter sowie zweidimensionale Konfidenz-Konturen für Paare von Parametern bestimmt werden\n",
    "können.\n",
    "\n",
    "*kafe2* enthält eine stand-alone Anwendung *kafe2go*, die Anpassungen ohne die Erstellung von\n",
    "eigenem Code ermöglicht;\n",
    "Daten, Modellfunktion und Optionenwerden dazu in einer Datei im  *yaml*-Format angegeben:\n",
    "\n",
    "`kafe2go <name>.yaml`\n",
    "\n",
    "*kafe2* kann aber ebenfalls und sehr viel flexibler über ein *python*-Interface verwendet werden.\n",
    "Eine Einführung in die Möglichkeiten gibt dieses Tutorial.\n",
    "Generell ist die Vorgehenweise folgende:\n",
    "\n",
    "  - Definition und Initialisierung eines Daten-Containers für die jeweilige Anpassung  \n",
    "    (Klassen IndexedContainer, XYContainer, HistContainer, UnbinnedContainer)\n",
    "  - Erzeugung eines geeigneten Objekts zur Durchführung der Anpassung, die den Datencontainer mit\n",
    "    einem Modell verbindet  (die allgemeine Klasse _Fit_ bzw. spezialisierte Klassen\n",
    "    _IndexedFit_, _XYFit_, _HistFit_, _UnbinnedFit_)\n",
    "  - Durchführung der Anpassung mittels $<$Fit_Objekt$>$.do_fit() und Ausgabe der Ergebnisse auf der\n",
    "    Konsole mittels $<$Fit_Objekt$>$.report() oder durch direkten Zugriff auf die\n",
    "    Ergebnis-Variablen des Fit-Objekts.\n",
    "  - Gegebenenfalls Erzeugung und Anzeige von Ergebnisgrafiken mit der generischen Klasse *Plot*.\n",
    "    \n",
    "**Die folgenden Beispiele zeigen die konkrete Vorgehensweise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allgemeine Einstellungen und nützliche Pakete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function  # python2-Kompatibilität\n",
    "import sys, os\n",
    "\n",
    "# Zeilen mit % oder %% am Anfang sind sogenannte \"magische Kommandos\",\n",
    "#  die den Zellentyp oder Optionen für die Anzeige von Grafiken festlegen \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports und Voreinstellungen für *kafe2*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafe2 import config, XYContainer, Fit, Plot\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# set better default figure size for kafe2\n",
    "# plt.rcParams['figure.figsize']=[12., 5.] \n",
    "#        !!!  must be done after importing kafe2 (will else be overwritten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Einfaches Beispiel zur Funktionsanpassung mit `kafe`2\n",
    "***\n",
    "\n",
    "Der folgende Code illustriert die Anpassung von Funktionen mit dem Anpassungswerkzeug `kafe2`\n",
    "```\n",
    "# Create an XYContainer object to hold the xy data for the fit.\n",
    "xy_data = XYContainer(x_data=[1.0, 2.0, 3.0, 4.0],\n",
    "                      y_data=[2.3, 4.2, 7.5, 9.4])\n",
    "# x_data and y_data are combined depending on their order.\n",
    "# The above translates to the points (1.0, 2.3), (2.0, 4.2), and (4.0, 9.4).\n",
    "\n",
    "# Important: Specify uncertainties for the data.\n",
    "xy_data.add_error(axis='x', err_val=0.1)\n",
    "xy_data.add_error(axis='y', err_val=0.4)\n",
    "\n",
    "# Create an Fit object from the xy data container.\n",
    "# By default, a linear function f=a*x+b will be used as the model function.\n",
    "line_fit = Fit(xy_data)\n",
    "\n",
    "# Perform the fit: Find values for a and b that minimize the\n",
    "#     difference between the model function and the data.\n",
    "line_fit.do_fit()  # This will throw an exception if no errors were specified.\n",
    "\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "line_fit.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "plot = Plot(fit_objects=line_fit)  # Create a kafe2 plot object.\n",
    "plot.plot()  # Do the plot.\n",
    "\n",
    "# Show the fit result.\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Fügen Sie den Code in die leere Zelle unten ein und führen Sie sie durch Eingabe von `shift+return`\n",
    "aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# einfaches Beispiel: Geradenanpassung mit kafe2\n",
    "# -> Code hier einfügen \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Korrelierte Unsicherheiten\n",
    "***\n",
    "\n",
    "Zur Illustration der Möglichkeiten zur Behandlung von Unsicherheiten fügen wir eine weitere\n",
    "korrelierte Unsicherheit der abhängigen Größen *y* ein:\n",
    "```\n",
    "xy_data.add_error(axis='y', err_val=0.3, correlation=1.)\n",
    "```\n",
    "\n",
    "Fügen Sie diese Zeile in den obigen Code ein.\n",
    "Die Ausgabe können Sie etwas übersichtlicher gestalten, indem Sie auf die Ausgabe der Daten und\n",
    "des Modells verzichten.\n",
    "Modifizieren Sie dazu die Parameter der *report()*-Methode:\n",
    "```\n",
    "line_fit.report(show_data=False, show_model=False)\n",
    "```\n",
    "Wiederholen Sie nun die Anpassung.\n",
    "\n",
    "Wie erwartet wirkt sich eine solche allen Datenpunkten gemeinsame Unsicherheit nicht auf die\n",
    "Steigung der Geraden, sondern nur auf den Parameter  *b* aus, dessen Unsicherheit nun größer wird\n",
    " - entsprechend der Wurzel aus der quadratischen Unsicherheit von +/-0.58 aus der ursprünglichen\n",
    "Anpassung und der zusätzlichen korrelierten Unsicherheit von 0.40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code aus dem vorigen Beispiel kopieren und ergänzen\n",
    "# ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Vergleich von zwei verschiedenen Modellen \n",
    "***\n",
    "\n",
    "Einfache, in den Parametern lineare Modelle reichen in der Praxis nicht aus. \n",
    "Das folgende Beispiel zeigt die Anpassung eines linearen und eines exponentiellen Modells an die\n",
    "gleichen Daten.\n",
    "\n",
    "Definition von zwei Modellfunktionen:\n",
    "```\n",
    "# To define a model function for kafe2 simply write it as a python function\n",
    "def linear_model(x, a, b):\n",
    "    # Our first model is a simple linear function\n",
    "    return a * x + b\n",
    "\n",
    "def exponential_model(x, A0=1., x0=5.):\n",
    "    # Our second model is a simple exponential function\n",
    "    # The kwargs in the function header specify initial parameter defaults.\n",
    "    return A0 * np.exp(x/x0)\n",
    "```\n",
    "\n",
    "Hier die Definition der Daten als kafe2 XYContainer:\n",
    "```\n",
    "# the data for this exercise\n",
    "x = [19.8, 3.0, 5.1, 16.1, 8.2,  11.7, 6.2, 10.1]\n",
    "y = [23.2, 3.2, 4.5, 19.9, 7.1, 12.5, 4.5, 7.2]\n",
    "data2 = XYContainer(x_data = x, y_data = y)\n",
    "data2.add_error(axis='x', err_val = 0.3)\n",
    "data2.add_error(axis='y', err_val = 0.15, relative = True)\n",
    "```\n",
    "\n",
    "Damit die Daten in der grafischen Ausgabe später klar gekennzeichnet werden, werden noch Namen\n",
    "für den Datensatz und die Achsenbeschriftungen gesetzt:\n",
    "```\n",
    "data2.label = 'Datenpunkte'\n",
    "data2.axis_labels=['x-Wert','y-Wert']\n",
    "```\n",
    "\n",
    "Dann wird je ein Fit-Objekt mit den beiden Modell-Funktionen und jeweils den gleichen Daten erzeugt:\n",
    "```\n",
    "# Create 2 Fit objects with the same data but with different model functions\n",
    "linear_fit = Fit(data2, model_function=linear_model)\n",
    "exponential_fit = Fit(data2, model_function=exponential_model)\n",
    "```\n",
    "\n",
    "Damit alles schöner aussieht, definieren wir noch LaTeX-Ausdrücke für die Funktionen, die Namen\n",
    "der Parameter und die Legende in der grafischen Ausgabe:\n",
    "```\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit.assign_parameter_latex_names(a='a', b='b')\n",
    "linear_fit.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "linear_fit.model_label = 'lineares Modell'\n",
    "exponential_fit.assign_parameter_latex_names(A0='A_0', x0='x_0')\n",
    "exponential_fit.assign_model_function_latex_expression(\"{A0} e^{{{x}/{x0}}}\")\n",
    "exponential_fit.model_label = 'exponentielles Modell'\n",
    "```\n",
    "\n",
    "Der Code zur Ausführung der Anpassungen sieht wie folgt aus:\n",
    "```\n",
    "# Perform the fits.\n",
    "linear_fit.do_fit()\n",
    "exponential_fit.do_fit()\n",
    "\n",
    "# Optional: Print out a report on the result of each fit.\n",
    "linear_fit.report()\n",
    "exponential_fit.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p = Plot(fit_objects=[linear_fit, exponential_fit], separate_figures=False)\n",
    "p.plot(fit_info=True)\n",
    "\n",
    "# Show the fit results.\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Fügen Sie den Code in die leere Zelle unten ein und führen Sie sie durch Eingabe von\n",
    "`shift+return` aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich von zwei Modellen mit kafe2\n",
    "# -> code hier einfügen \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hypothesentest zur Bewertung der Modelle\n",
    "***\n",
    "\n",
    "Die grafische Ausgabe lässt nicht klar erkennen, welches der Modelle akzeptabel ist. \n",
    "Dazu kann ein Hypothesentest ausgeführt werden, der die sogenannte $\\chi^2$-Wahrscheinlichkeit\n",
    "angibt - also die Wahrscheinlichkeit dafür, einen schlechteren Wert von $\\chi^2$ am Minimum zu\n",
    "erhalten als den beobachteten.\n",
    " \n",
    "Berechnet wird er aus der kumulativen Verteilungsdichte der Chi2-Funktion:\n",
    "```\n",
    "from scipy import stats\n",
    "\n",
    "def chi2prob(chi2, ndf):\n",
    "  \"\"\" chi2-probability\n",
    " \n",
    "    Args:\n",
    "      * chi2: chi2 value\n",
    "      * ndf: number of degrees of freedom\n",
    "\n",
    "    Returns:\n",
    "      * float: chi2 probability\n",
    "  \"\"\"\n",
    "\n",
    "  return 1.- stats.chi2.cdf(chi2, ndf)\n",
    "```\n",
    "\n",
    "Geben Sie den Code für die $\\chi^2$-Wahrscheinlichkeit in die leere Zeile unten ein und\n",
    "überprüfen Sie die beiden Ergebnisse, die Sie oben erhalten haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung der Qualität der Anpassungen\n",
    "# -> code hier eingeben\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Untersuchung des nicht-linearen Modells\n",
    "***\n",
    "\n",
    "Bei Modellfunktionen, die nicht-linear in den Parametern sind, ist die $\\chi^2$-Verteilung um das\n",
    "Minimum nur näherungsweise eine Parabel, bisweilen weicht sie sogar stark davon ob.\n",
    "Ob die Abweichungen vernachlässigbar klein sind, kann mit Hilfe der Profile-Likelihood und durch\n",
    "die Darstellung von Konfidenz-Konturen überprüft werden.\n",
    "```\n",
    "from kafe2 import ContoursProfiler\n",
    "\n",
    "# Create contour plot and profiles for the exponential fit\n",
    "cpf = ContoursProfiler(exponential_fit)\n",
    "cpf.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Geben Sie das Code-Beispiel in der Zeile unten ein und überprüfen Sie damit die Anpassung des\n",
    "exponentiellen Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung der nichtlinearen Anpassung\n",
    "# -> code hier eingeben\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Asymmetrische Parameterunsicherheiten\n",
    "***\n",
    "\n",
    "Wenn die Abweichungen groß sind, müssen asymmetrische Unsicherheiten angegeben werden.\n",
    "Dazu wird in der *report*-Funktion der Fit-Klasse die Option *asymmetric_parameter_errors=True*\n",
    "gesetzt.\n",
    "```\n",
    "exponential_fit.report(asymmetric_parameter_errors=True)\n",
    "```\n",
    "\n",
    "Es empfiehlt sich, in solchen Fällen mit stark asymmetrischen Parameterunsicherheiten die\n",
    "Konturen zu dokumentieren, wenn mehr als ein Parameter von Interesse ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code zur Ausgabe asymmetrischer Parameter eingeben\n",
    "# ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Beeinflussung der grafischen Ausgabe\n",
    "***\n",
    "\n",
    "Die grafische Ausgabe war noch nicht in allen Belangen optimal. \n",
    "Es wurden in der Legende z.B. zwei Datensätze angeben, obwohl es für beide Modelle nur den\n",
    "gleichen gab.\n",
    "Außerdem lassen sich Markereigenschaften und Farben anpassen.\n",
    "\n",
    "Zur Beeinflussung der Grafik enhält *kafe2* eine Methode `Plot.customize()`, mit deren Hilfe für\n",
    "die verschiedenen Grafikelemente (*plot_types*: 'data', 'model_line', 'model_error_band',\n",
    "'ratio', 'ratio_error_band') Werte für *matplotlib*-Parameter angegeben werden können.\n",
    "\n",
    "Die für einen *plot_type* relevanten Parameter und deren momentane Werte lassen sich über eine\n",
    "Funktion der *Plot*-Klasse anzeigen:\n",
    "```\n",
    "p.get_keywords('model_error_band')\n",
    "```\n",
    "Wenn, wie in diesem Beispiel, mehrere Fits in einer Grafik enthalten sind, werden die Parameter\n",
    "als Tuple in der Form *(index, wert)* angegeben.\n",
    "\n",
    "Die verwendeten Namen für Objekte und mögliche Werte entstprechen den Bezeichnungen in der\n",
    "Konfigurationsdatei *matplotlibrc* für *matplotlib*.\n",
    "\n",
    "Zur Änderung des Namens für den Datensatz und die Unterdrückung der zweiten Ausgabe dient\n",
    "folgender Aufruf:\n",
    "```\n",
    "p.customize('data', 'label', [(0, \"test data\"),(1, '__del__')])\n",
    "```\n",
    "\n",
    "Auch Marker-Typ, Größe und Farbe des Markers und der Fehlerbalken lassen sich anpassen:\n",
    "```\n",
    "# data\n",
    "p.customize('data', 'marker', [(0, 'o'), (1,'o')])\n",
    "p.customize('data', 'markersize', [(0, 5), (1, 5)])\n",
    "p.customize('data', 'color', [(0, 'blue'), (1,'blue')]) # note: although 2nd label is suppressed\n",
    "p.customize('data', 'ecolor', [(0, 'blue'), (1, 'blue')]) # note: although 2nd label is suppressed\n",
    "```\n",
    "\n",
    "Ebenso können die entsprechenden Werte für die Modellfunktion angepasst werden:\n",
    "```\n",
    "# model\n",
    "p.customize('model_line', 'color', [(0, 'orange'),(1, 'lightgreen')])\n",
    "p.customize('model_error_band', 'label', [(0, r'$\\pm 1 \\sigma$'),(1, r'$\\pm 1 \\sigma$')])\n",
    "p.customize('model_error_band', 'color', [(0, 'orange'),(1, 'lightgreen')])\n",
    "```\n",
    "\n",
    "Es ist auch möglich, Parameter über die *matplotlib*-Funktionen zu verändern. \n",
    "Um die Größe der Achsenbeschriftungen zu ändern, verwendet man z.B. folgende Aufrufe:\n",
    "```\n",
    "# Größe der Achsenbeschriftungen\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=20, titlesize=25)\n",
    "```\n",
    "\n",
    "Natürlich muss nach diesen Änderungen die Ausgabegrafik neu erzeugt und angezeigt werden:\n",
    "```\n",
    "p.plot()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code zum Testen hier eingeben:\n",
    "# --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Ausgabe der Anpassungsergebnisse als Variable \n",
    "***\n",
    "\n",
    "In vielen Anwendungen ist es nötig, die Ausgabe einer Anpassung im Programmcode weiter zu verwenden.\n",
    "Dazu dient die *kafe2*-Funktion *Fit.get_result_dict()*, die ein python-Dictionary mit den\n",
    "Fit-Ergebnissen zurückgibt.\n",
    "\n",
    "Zum Beispiel:\n",
    "```\n",
    "r = <Fit_object>.get_result_dict()\n",
    "```\n",
    "\n",
    "Eine formatierte Ausgabe erhält man mit folgender Zeile:\n",
    "```\n",
    "print(\"\\n\".join(\"{}\\t{}\".format(k, v) for k, v in result_0.items()))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe hier testen \n",
    "# --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Nicht-Linearität durch Fehler in *x* - Richtung\n",
    "***\n",
    "\n",
    "Wenn die Fehler in x-Richtung vergrößert werden, wird auch die Anpassung einer Geraden zu einem\n",
    "nicht-linearen Problem.\n",
    "Zur Illustration wiederholen wir die gleiche Anpassung wie oben mit vergrößerten Unsicherheiten\n",
    "auf die x-Werte:\n",
    "```\n",
    "# the data for this exercise\n",
    "data3 = XYContainer(x_data = x, y_data = y)\n",
    "data3.add_error(axis='x', err_val = 1.0) # was 0.3 before\n",
    "data3.add_error(axis='y', err_val = 0.15, relative = True)\n",
    "\n",
    "# Create 2 Fit objects with the same data but with different model functions\n",
    "linear_fit2 = Fit(data3, model_function=linear_model)\n",
    "\n",
    "# Optional: Assign LaTeX strings to parameters and model functions.\n",
    "linear_fit2.assign_parameter_latex_names(x='x', a='a', b='b')\n",
    "linear_fit2.assign_model_function_latex_expression(\"{a}{x} + {b}\")\n",
    "\n",
    "# Perform the fits.\n",
    "linear_fit2.do_fit()\n",
    "\n",
    "# Optional: Print out a report on the result of each fit.\n",
    "#linear_fit2.report()\n",
    "\n",
    "# Optional: Create a plot of the fit results using Plot.\n",
    "p2 = Plot(fit_objects = linear_fit2)\n",
    "\n",
    "p2.plot(fit_info=True)\n",
    "\n",
    "# Create contour plot and profiles for the linear fit\n",
    "cpf2 = ContoursProfiler(linear_fit2)\n",
    "cpf2.plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "\n",
    "# Show the fit results.\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obigen Code hier eingeben:\n",
    "# --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kleine Übung: Hinzufügen eines quadratischen Modells\n",
    "\n",
    "Als kleine Übung soll ein weiteres, quadratisches Modell, $y(x) = ax^2 + b x + c$, hinzugefügt\n",
    "werden und zusammen mit dem linearen und dem exponentiellen Modell in einer Grafik dargestellt\n",
    "werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eingenen Code hier eingeben:\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Besonderheiten komplexer (nichtlinearer) Modelle\n",
    "---\n",
    "\n",
    "Als weiteres Beispiel für eine nicht-lineare Anpassung dient eine gedämpfte Schwingung eines\n",
    "Fadenpendels.\n",
    "Die zugehörigen Messdaten sind in der folgenden Code-Zelle enthalten:\n",
    "```\n",
    "#the data\n",
    "t = [ ... ]\n",
    "t_errors = 0.05\n",
    "\n",
    "a = [ ... ]\n",
    "a_errors = 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data:\n",
    "t = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0,\n",
    "     10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0, 14.5, 15.0, 15.5, 16.0, 16.5, 17.0, 17.5, 18.0, 18.5, 19.0,\n",
    "     19.5, 20.0, 20.5, 21.0, 21.5,22.0, 22.5, 23.0, 23.5, 24.0, 24.5, 25.0, 25.5, 26.0, 26.5, 27.0, 27.5, 28.0,\n",
    "     28.5, 29.0, 29.5, 30.0, 30.5, 31.0, 31.5, 32.0, 32.5, 33.0, 33.5, 34.0, 34.5, 35.0, 35.5, 36.0, 36.5, 37.0,\n",
    "     37.5, 38.0, 38.5, 39.0, 39.5, 40.0, 40.5, 41.0, 41.5, 42.0, 42.5, 43.0, 43.5, 44.0, 44.5, 45.0, 45.5, 46.0,\n",
    "     46.5, 47.0, 47.5, 48.0, 48.5, 49.0, 49.5, 50.0, 50.5, 51.0, 51.5, 52.0,52.5, 53.0, 53.5, 54.0, 54.5, 55.0,\n",
    "     55.5, 56.0, 56.5, 57.0, 57.5, 58.0, 58.5, 59.0, 59.5, 60.0]\n",
    "t_errors = 0.05\n",
    "\n",
    "a = [ 6.06,  5.17,  3.29,  0.64, -2.26, -4.56, -5.74, -5.58, -4.12, -1.62,\n",
    "      1.11,  3.56,  5.12,  5.43,  4.41,  2.53, -0.18, -2.78, -4.65, -5.5,\n",
    "     -5.04, -3.25, -0.75,  1.79,  3.88,  5.31,  5.2,   3.92,  1.74, -0.85,\n",
    "     -3.13, -4.71, -5.06, -4.26, -2.48, -0.13,  2.19,  4.07,  4.9,   4.64,\n",
    "      3.16,  1.17, -1.54, -3.26, -4.59, -4.64, -3.69, -1.83,  0.38,  2.76,\n",
    "      4.16,  4.58,  4.13,  2.45,  0.28, -1.8,  -3.53, -4.43, -4.31, -3.03,\n",
    "     -1.05,  1.06,  2.79,  3.97,  4.4,   3.37,  1.92, -0.14, -2.29, -3.7,\n",
    "     -4.28, -3.84, -2.44, -0.59,  1.27,  3.11,  3.9,   4.02,  2.85,  1.21,\n",
    "     -0.64, -2.51, -3.41, -3.84, -3.34, -1.75, -0.17,  1.85,  3.23,  3.72,\n",
    "      3.4,   2.54,  0.67, -1.13, -2.8,  -3.77, -3.65, -2.89, -1.43,  0.42,\n",
    "      2.2,   3.26,  3.42,  3.25,  1.88,  0.33, -1.35, -3.02, -3.41, -3.32,\n",
    "     -2.2,  -0.77,  0.92,  2.44,  3.31,  3.44,  2.77,  1.25, -0.13, -1.69, -2.78 ]\n",
    "a_errors = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Amplitude in Abhängigkeit von der Zeit ist durch folgende Modellfunktion gegeben:\n",
    "```\n",
    "# Model function for a pendulum as a one-dimensional, damped harmonic oscillator with zero initial speed\n",
    "# x = time, y_0 = initial_amplitude, l = length of the string,\n",
    "# r = radius of the steel ball, g = gravitational acceleration, c = damping coefficient\n",
    "def damped_harmonic_oscillator(s, a0, l, r, g, c):\n",
    "  l_total = l + r # effective length of the pendulum = length of the string + radius of the steel ball\n",
    "  omega_0 = np.sqrt(g / l_total) # phase speed of an undamped pendulum\n",
    "  omega_d = np.sqrt(omega_0 ** 2 - c ** 2) # phase speed of a damped pendulum\n",
    "  return a0 * np.exp(-c * s) * (np.cos(omega_d * s) + c / omega_d * np.sin(omega_d * s))\n",
    "```\n",
    "\n",
    "Datencontainer und Fit-Objekt werden wie üblich erzeugt:\n",
    "```\n",
    "# create data container\n",
    "data3 = XYContainer(t, a)\n",
    "data3.add_error(axis='x', err_val = t_errors )\n",
    "data3.add_error(axis='y', err_val = a_errors)\n",
    "data3.axis_labels = ('Time t (s)', 'Amplitude A (°)') \n",
    "\n",
    "# Create fit object from data and model function\n",
    "fit = Fit(data3, damped_harmonic_oscillator)\n",
    "```\n",
    "\n",
    "Das Modell enthält eine Anzahl an Parametern, die durch \"Hilfsmessungen\" festgelegt sind. \n",
    "```\n",
    "# Relevant physical magnitudes and their uncertainties\n",
    "lm, delta_lm = 10.000, 0.002     # length of the string, l = 10.0 +- 0.002 m\n",
    "rm, delta_rm = 0.052, 0.001      # radius of the steel ball, r = 0.052 +- 0.001 m\n",
    "#              Note that the uncertainty on y_0 is relative to y_0\n",
    "a0m, delta_a0m = 6.0, 0.01   # amplitude of the steel ball at x=0 in degrees, y_0 = 6 +- 1% degrees\n",
    "```\n",
    "\n",
    "In der Anpassung wird dies berücksichtigt, indem die entsprechenden Parameter sowohl als\n",
    "Parameter der Anpassung als auch als zusätzliche Datenpunkte berücksichtigt werden.\n",
    "In kafe2 werden solche durch Messungen eingeschränkte Parameter mit Hifle der Methode\n",
    "*Fit.add_parameter_constraint()* berücksichtigt und deren Unsicherheiten in das Ergebnis der\n",
    "Anpassung propagiert:\n",
    "```\n",
    "# Constrain model parameters to measurements\n",
    "fit.add_parameter_constraint(name='l', value=lm, uncertainty=delta_lm)\n",
    "fit.add_parameter_constraint(name='r', value=rm, uncertainty=delta_rm)\n",
    "fit.add_parameter_constraint(name='a0', value=a0m, uncertainty=delta_a0m, relative=True)\n",
    "```\n",
    "\n",
    "Als Alternative könnte man die Parameter mit der Methode *Fit.fix_parameter()* auf feste Werte\n",
    "fixieren;\n",
    "die Unsicherheiten auf das Endergebnis der Anpassung müssten dann allerdings mit Hilfe der\n",
    "klassischen Fehlerfortpflanzung berechnet werden.\n",
    "\n",
    "Als weitere Besonderheit bei nichtlinearen Anpassungen ist zu beachten, dass es häufig\n",
    "Nebenminima der Kostenfunktion gibt - die Konvergenz zum globalen Minimum kann also nicht\n",
    "garantiert werden.\n",
    "Es ist daher notwendig, \"vernünftige\" Start-Parameter für die Anpassung zu wählen.\n",
    "Dies geschieht mit Hilfe der Funktion *Fit.set_parameter_values)*:\n",
    "```\n",
    "g_initial = 9.81 # initial guess for g\n",
    "c_initial = 0.01 # initial guess for c\n",
    "fit.set_parameter_values(g = g_initial, c = c_initial)\n",
    "\n",
    "fit.set_parameter_values(a0 = a0m, l = lm, r = rm)\n",
    "```\n",
    "\n",
    "Wenn die Startwerte gänzlich unbekannt sind, sollten Werte in einem großen Bereich ausprobiert\n",
    "werden, um zu überprüfen, ob die Anpassungen jeweils zum gleichen Minimum konvergieren. \n",
    "\n",
    "Nach diesen Vorbereitungen kann die Anpassung wie üblich vorgenommen werden. \n",
    "Im folgenden Code-Beispiel wird auch gezeigt, wie man direkt auf die Fit-Ergebnisse zugreift,\n",
    "fall sie im Programm weiter verarbeitet werden sollen oder eine spezifische eigene Ausgabe\n",
    "erfolgen soll.\n",
    "```\n",
    "# Perform the fit\n",
    "fit.do_fit()\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "#fit.report(show_data=False, show_model=False, show_fit_results=True)\n",
    "\n",
    "# Optional: Print out a report on the fit results on the console.\n",
    "#fit.report(show_data=False, show_model=False, show_fit_results=True)\n",
    "#    custom printout of results\n",
    "print(\"cost function at minimum: %.4g \" %fit.cost_function_value, \" numer of degrees of freedom:\", fit.ndf)\n",
    "print(\" --> probability: %.1f%%\" %(chi2prob(fit.cost_function_value, fit.ndf)*100) )\n",
    "print(\"parameter names:\\n\", fit.parameter_names)\n",
    "np.set_printoptions(precision=5, suppress=False)\n",
    "print(\"prameter values:\\n\", fit.parameter_values)\n",
    "print(\"parameter uncertainties:\\n\",fit.parameter_errors)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"correlation matrix:\\n\", fit.parameter_cor_mat )\n",
    "      \n",
    "# Optional: plot the fit results\n",
    "plot = Plot(fit)\n",
    "plot.plot(fit_info=True)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code hier eingeben\n",
    "# --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Aufbau einer Kovarianz-Matrix aus einzelnen Unsicherheiten\n",
    "---\n",
    "\n",
    "Behandelt werden: \n",
    "  - der Umgang mit komplexen Unsicherheiten\n",
    "  \n",
    "Eine der besonderen Stärken von _kafe2_ ist die Unterstützung von korrelierten Unsicherheiten.\n",
    "Damit sind Beiträge zur Unsicherheit gemeint, die einige oder alle Werte in gleicher Weise\n",
    "beeinflussen - z.B. weil sie mit dem gleichen, mit einer systematischen Unsicherheit behafteten\n",
    "Messgerät aufgezeichnet wurden.\n",
    "Häufig handelt es sich also um gemeinsame Unsicherheiten von Gruppen von Messwerten.\n",
    "\n",
    "Zur Angabe von Unsicherheiten dient die Funktion\n",
    "> `add_error**( [axis], err_val, name=None, correlation=0, relative=False)`  \n",
    "  Add an uncertainty source to the data container. Returns an error id which\n",
    "  uniquely identifies the created error source.  \n",
    "  **Parameters**  \n",
    "  • axis (str or int) – 'x'/0 or 'y'/1  \n",
    "  • err_val (float or iterable of float) – pointwise uncertainty/uncertainties for all data points  \n",
    "  • name (str or None) – unique name for this uncertainty source. If None, the name\n",
    "    of the error source will be set to a random alphanumeric string.  \n",
    "  • correlation (float) – correlation coefficient between any two distinct data points  \n",
    "  • relative (bool) – if True, err_val will be interpreted as a relative uncertainty  \n",
    "  **Returns** error name  \n",
    "  **Return type** str  \n",
    "\n",
    "Sie gehört zur Container-Klasse, kann aber auch über eine Fit-Klasse aufgerufen werden.\n",
    "Mit diesem recht einfachen Interface lassen sich sowohl unabhängige Unsicherheiten als auch\n",
    "gemeinsame absolute oder relative Unsicherheiten von Datenpunkten angeben.\n",
    "Die angegebenen Unsicherheiten werden in eine Kovarianzmatrix der Datenpunkte umgewandelt.\n",
    "Bei mehrfachem Aufruf werden die sich ergebenden Kovarianzmatrizen addiert (wie es den Regeln der\n",
    "elementaren Fehlerfortpflanzung entspricht).\n",
    "\n",
    "Ein sehr einfach gehaltenes Beispiel soll das illustrieren.\n",
    "Wir betrachten die Mittelung von vier Werten, die von zwei Gruppen mit unterschiedlichen\n",
    "Messverfahren durchgeführt wurden.\n",
    "Jede der beiden Gruppen gibt zwei Messungen an; in der ersten Gruppe gibt es eine absolute, den\n",
    "beiden Messungen gemeinsame Unsicherheit; die zweite Gruppe gibt eine zwischen ihren beiden\n",
    "Messungen korrelierte relative - also z.B. durch einen Skalierungsfeher verursachte -\n",
    "Unsicherheit an.\n",
    "Den Messungen liegt weiterhin eine gemeinsame (theoretische) Annahme zu Grunde, die zu einer\n",
    "allen Messungen gemeinsamen, absoluten Unsicherheit führt.\n",
    "\n",
    "Bei diesem einfachen Problem nutzen wir die einfachste Datenstruktur von *kafe2*,\n",
    "den _IndexedContainer_, zur Bereitstellung der Daten:  \n",
    "```\n",
    "from kafe2 import IndexedContainer\n",
    "idx_data = IndexedContainer([5.3, 5.2, 4.7, 4.8])  \n",
    "```\n",
    "Als Modell wählen wir eine konstante Funktion:\n",
    "```\n",
    "# the very simple \"model\"\n",
    "def average (a):\n",
    "  return a\n",
    "```\n",
    "\n",
    "Die Unsicherheiten werden dann folgendermaßen angegeben \n",
    "                (Anm.: In diesem Fall entfällt die Angabe des '_axis_`-Parameters!):\n",
    "  1. jeder Messung eigene, unabhängige Unsicherheit  \n",
    "     `err_stat = idx_data.add_error([.2, .2, .2, .2])`\n",
    "  2. die den ersten beiden Werten gemeinsame Unsicherheit  \n",
    "     `err_syst12 = idx_data.add_error([.175, .175, 0., 0.], correlation = 1.)`\n",
    "  3. die den letzten beiden Werten gemeinsame, relative Unsicherheit  \n",
    "     `err_syst34 = idx_data.add_error([0., 0., .05, 0.05], correlation = 1., relative=True)`\n",
    "  4. die allen Werten gemeinsame Unsicherheit   \n",
    "     `err_syst = idx_data.add_error(0.15, correlation = 1.)`\n",
    "\n",
    "Wir sollten noch passende Namen für die Daten angeben:\n",
    "```\n",
    "# Namen vergeben\n",
    "idx_data.label = 'Testdaten'\n",
    "idx_data.axis_labels = [None,'Meßwert (a.u.)']\n",
    "```\n",
    "\n",
    "Das Ausführen der Anpassung ist mittlerweile ja gut bekannt:\n",
    "```\n",
    "# set up the fit\n",
    "ifit = Fit(idx_data, average)\n",
    "ifit.model_label = 'Mittelwert'\n",
    "\n",
    "# perform the fit#\n",
    "ifit.do_fit()\n",
    "```\n",
    "\n",
    "Die Ergebisse erhält man natürlich mit der _report()_-Funktion, ggf. auch als grafische Darstellung:\n",
    "```\n",
    "# report results\n",
    "ifit.report()\n",
    "p=Plot(ifit)\n",
    "p.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Die Beschriftung der x-Achse ist noch nicht passend - hier sollten nur die Indizes der Messungen\n",
    "stehen.\n",
    "Mit ein wenig Hilfe von *matplotlib* lässt sich das erreichen.\n",
    "Dazu muss auf das *axis*-Objekts der erzeugten Grafik zugegriffen und die entsprechende Anpassung\n",
    "durchgeführt werden.\n",
    "Dazu folgenden Code nach der Zeile *p.plot()* vor *plt.show()* eingefügen:\n",
    "```\n",
    "# illustrate some a-posteriory fixes to plot layout by accessing the axis object\n",
    "_ax = p.axes[0]['main']\n",
    "_ax.set_xticks(range(4)) # Integer axis ticks\n",
    "```\n",
    "\n",
    "Wenn ein Problem mehrere Beiträge zur Gesamtunsicherheit enthält, möchte man in der Regel gerne\n",
    "studieren, welchen Einfluss einzelne Komponenten haben.\n",
    "Dazu kann man komfortabel mit den Funktionen *disable_error()* und *enable_error()* arbeiten und\n",
    "entsprechende Anpassungen durchführen:\n",
    "```\n",
    "print(\"disabling common sysytematic error\")\n",
    "idx_data.disable_error(err_syst)\n",
    "_ifit = Fit(idx_data, average) \n",
    "_ifit.do_fit()\n",
    "_ifit.report()\n",
    "#      do not forget to switch on again \n",
    "idx_data.enable_error(err_syst)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code hier eingeben\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Anwendung aus der Praxis: Anpassung einer Breit-Wigner-Resonanz \n",
    "---\n",
    "\n",
    "Behandelt werden: \n",
    "  - der Umgang mit komplexen Unsicherheiten\n",
    "  - das Erzeugen einer ansprechenden grafischen Ausgabe\n",
    "  - das Studium des Einflusses einzelner Fehlerkomponenten\n",
    "\n",
    "Typischerweise sind die Unsicherheiten der Messdaten deutlich komplexer als in den bisher\n",
    "behandelten Beispielen.\n",
    "Meist sind Unsicherheiten in Ordinate und Abszisse vorhanden, und zusätzlich zu den unabhängigen\n",
    "Unsicherheiten eines jeden Datenpunktes gibt es allen gemeinsame, korrelierte Unsicherheiten.\n",
    "\n",
    "Mit der Methode *add_error()* bzw. *add_matrix_error()* können Unsicherheiten auf die 'x'- und\n",
    "'y'-Daten spezifiziert werden, entweder in Form von unabhängigen bzw. korrelierten, relativen oder\n",
    "absoluten Unsicherheiten aller oder Gruppen von Messwerten.\n",
    "Oder durch die Angabe der vollständigen Kovarianz- oder Korrelations-Matrix.\n",
    "Alle so spezifizierten Unsicherheiten gehen in die globale Kovarianzmatrix für die Anpassung ein.\n",
    "\n",
    "Als Beispiel betrachten wir Messungen eines Wirkungsquerschnitts als Funktion der Energie in der\n",
    "Nähe einer Resonanz.\n",
    "Es handelt sich dabei um kombinierte Messdaten der vier Experimente am Beschleuniger LEP des\n",
    "CERN, die auf Effekte durch Photon-Abstrahlung korrigiert wurden:\n",
    "Messungen des hadronischen Wirkungsquerschnitts $\\sigma_{e^+e^- \\to {\\rm hadrons}}$ als Funktion\n",
    "der Schwerpunktsenergie $E_{CM}$.\n",
    "```\n",
    "## Data:\n",
    "# Center-of-mass energy E (GeV)\n",
    "E = [ 88.387, 89.437, 90.223, 91.238, 92.059, 93.004, 93.916 ]  \n",
    "E_errors = [ 0.005, 0.0015, 0.005, 0.003, 0.005, 0.0015, 0.005 ]\n",
    "ECor_abs = 0.0017  # correlated absolute errors\n",
    "\n",
    "# hadronic cross section with photonic corrections applied (nb)\n",
    "sig = [6.803, 13.965, 26.113, 41.364, 27.535, 13.362, 7.302 ]  \n",
    "sig_errors = [ 0.036, 0.013, 0.075, 0.010, 0.088, 0.015, 0.045 ]\n",
    "sigCor_rel = 0.0007 \n",
    "```\n",
    "\n",
    "Als Modell verwenden wir eine modifizierte Breit-Wigner-Resonanz mit von der Schwerpunktsenergie\n",
    "abhängiger Breite (\"$s$-dependent width\", mit $s = E_{CM}^2$):\n",
    "```\n",
    "## Model:\n",
    "# Breit-Wigner with s-dependent width\n",
    "def BreitWigner(E, s0 = 41.0, M = 91.2, G = 2.5):\n",
    "    s = E*E\n",
    "    Msq = M*M\n",
    "    Gsq = G*G\n",
    "    return s0*s*Gsq/((s-Msq)*(s-Msq)+(s*s*Gsq/Msq))\n",
    "```\n",
    "\n",
    "Der Daten-Container mit den Unsicherheiten wird wie folgt erzeugt:\n",
    "```\n",
    "BWdata= XYContainer(ECM, sig)\n",
    "# add independent errors\n",
    "error_name_sig = BWdata.add_error(axis='x', name = 'deltaE', err_val = E_errors )   \n",
    "error_name_E = BWdata.add_error(axis='y', name = 'deltaSig', err_val = sig_errors )\n",
    "# add fully correlated, absolute Energy errors\n",
    "error_name_ECor = BWdata.add_error(axis='x', name='Ecor',err_val = ECor_abs, correlation = 1.) \n",
    "# add fully correlated, relative cross section errors\n",
    "error_name_sigCor = BWdata.add_error(axis='y', name='sigCor', \n",
    "                            err_val = sigCor_rel, correlation = 1., relative=True) \n",
    "```\n",
    "\n",
    "Ob es sich um unabhängige oder korrelierte Unsicherheiten handelt, wird durch den Parameter\n",
    "*correlation* bestimmt;\n",
    "für unabhängige Unsicherheiten ist er Null, für allen Dateneinträgen gemeinsame Unsicherheiten\n",
    "ist er Eins.\n",
    "Werte zwischen 0. und 1. sind ebenfalls zulässig;\n",
    "allerdings wird in der Praxis die Kovarianzmatreix zur Beschreibung der Gesamtunsicherheit meist\n",
    "aus unkorrelierten und vollständig korrelierten Komponenten zusammengesetzt.\n",
    "Die in der Fuktion *add_error* angegebenen Namen erlauben es, später auf die einzelnen\n",
    "Fehlerkomponenten zuzugreifen.\n",
    "\n",
    "Anpassung und Ergebnisausgabe folgen der üblichen Vorgehensweise:\n",
    "```\n",
    "BWfit = Fit(BWdata, BreitWigner)\n",
    "BWfit.do_fit()\n",
    "BWfit.report()\n",
    "# Optional: plot the fit results\n",
    "BWplot = Plot(BWfit)\n",
    "BWplot.plot(fit_info=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Verschönerung der grafischen Ausgabe**  \n",
    "Damit die Art der Daten klar beschrieben ist, sollten noch passende Namen vergeben werden.\n",
    "Die Zeilen unten müssen dazu vor der Erzeugung des *Fit*-Objekts eingefügt werden.\n",
    "```\n",
    "BWdata.label = 'QED-corrected hadronic cross-sections'\n",
    "BWdata.axis_labels = ('CM Energy (GeV)', '$\\sigma_h$ (nb)' )\n",
    "```\n",
    "\n",
    "Es sollte auch noch ein passender Name für das Modell in der Legende für die grafische Ausgabe\n",
    "gesetzt werden.\n",
    "Dazu wird die Zeile unten nach der Erzeugung des *Fit*-Objekts eingesetzt:\n",
    "```\n",
    "BWfit.model_label = 'Beit-Wigner with s-dependent width'\n",
    "```\n",
    "\n",
    "Falls ein schön gesetzter Ausdruck für die Modellfunktion gewünscht wird, können LaTeX-Namen für\n",
    "das Modell, die Parameter und die Modellfunkton gesetzt werden:\n",
    "```\n",
    "# set LaTeX names for printout in info-box\n",
    "BWfit.assign_parameter_latex_names(E='E', s0=r'{\\sigma^0}', M=r'{M_Z}', G=r'{\\Gamma_Z}')\n",
    "BWfit.assign_model_function_latex_name(r'\\sigma^{\\rm ew}_{e^+e^-\\to{\\rm hadrons}}')\n",
    "BWfit.assign_model_function_latex_expression(\n",
    "               r'{s0}\\frac{{ {E}^2{G}^2}}{{({E}^2-{M}^2)^2+({E}^4{G}^2/{M}^2)}}')\n",
    "```\n",
    "\n",
    "Anmerkung: Die Verdopplung der Klammern \"{\" und \"}\" ist notwendig, weil sie in *kafe2*,\n",
    "ähnlich wie in der Python *format*-Funktion, auch zur Übergabe von Parametern genutzt werden.\n",
    "\n",
    "Wünschenswert ist noch ein passenderer Name für das Band zur Anzeige der Modellunsicherheit.\n",
    "Dazu die folgende Zeile nach der Erzeugung des *Plot*-Pbjekts einfügen:\n",
    "```\n",
    "BWplot.customize('model_error_band', 'label', [r'$\\pm 1\\sigma$'])\n",
    "```\n",
    "\n",
    "In diesem Beispiel ist allerdings die Modellunsicherheit extrem klein (weit unter 0.1%) und daher\n",
    "in der Grafik nicht sichtbar.\n",
    "Unterdrücken kann man die Ausgabe in der Legende mit folgender Angabe:\n",
    "```\n",
    "BWplot.customize('model_error_band', 'label', ['__del__'])\n",
    "```\n",
    "\n",
    "Manchmal wird das Unsicherheitsband von der Line überdeckt; in solchen Fällen solle eine\n",
    "gestrichelte oder gepunktete Linie für das Modell verwendet werden:\n",
    "```\n",
    "BWplot.customize('model_line', 'linestyle', ['--'])\n",
    "```\n",
    "\n",
    "Nun sollten noch die Ränder des Plot-Bereiches angepasst werden, damit ein ästhetisch guter\n",
    "Eindruck erreicht wird.\n",
    "Dies gelingt über den direkten Zugriff auf das *axis*-Ojekt und Anwendung von\n",
    "*matplotlib*-Methoden.\n",
    "Die Zeilen unten werden dazu vor *plt.show()* eingefügt:\n",
    "```\n",
    "# illustrate some a-posteriory fixes to plot layout by accessing the axis object\n",
    "def scale_plot_range(lims, sf):\n",
    "   d = 0.5*(sf-1.)*(lims[1]-lims[0])\n",
    "   return [lims[0]-d, lims[1]+d]\n",
    "_ax = BWplot.axes[0]['main']\n",
    "_ax.set_xlim(scale_plot_range(_ax.get_xlim(), 1.1))\n",
    "_ax.set_ylim(scale_plot_range(_ax.get_ylim(), 1.1))\n",
    "```\n",
    "\n",
    "Da es sich um eine nichtlineare Anpassung handelt, sollten noch Profile-Likelihood \n",
    "und Konfidenz-Konturen angezeigt werden.\n",
    "Die folgende Zeile muss dazu vor *plt.show()* eingefügt werden:\n",
    "```\n",
    "ContoursProfiler(BWfit).plot_profiles_contours_matrix(show_grid_for='contours')\n",
    "``` \n",
    "!!! Geduld: die Berechnung der Konturen ist rechenaufwändig und dauert eine gewisse Zeit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' the data for the Breit-Wigner example'''\n",
    "# Center-of-mass energies E (GeV)\n",
    "ECM = [ 88.387, 89.437, 90.223, 91.238, 92.059, 93.004, 93.916 ]  \n",
    "E_errors = [ 0.005, 0.0015, 0.005, 0.003, 0.005, 0.0015, 0.005 ]\n",
    "ECor_abs = 0.0017  # correlated absolute errors\n",
    "\n",
    "# hadronic cross sections with photonic corrections applied (nb)\n",
    "sig = [6.803, 13.965, 26.113, 41.364, 27.535, 13.362, 7.302 ]  \n",
    "sig_errors = [ 0.036, 0.013, 0.075, 0.010, 0.088, 0.015, 0.045 ]\n",
    "sigCor_rel = 0.0007 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obigen Code hier eingeben \n",
    "# --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Studium des Einflusses einzelner Fehlerkomponenten**  \n",
    "Um den Einfluss einzelner Fehlerkomponenten auf das Ergebnis zu untersuchen, kann man einzelne\n",
    "Quellen von Unsicherheiten mit der Methode *disable_error()* abschalten und eine neue Anpassung\n",
    "ausführen, hier gezeigt für die korrelierte Unsicherheit der Schwerpunktsenergien:\n",
    "```\n",
    "print('!!!  disabling error component ', error_name_ECor)\n",
    "BWfit.disable_error(error_name_ECor)\n",
    "BWfit.do_fit()\n",
    "BWfit.report(show_data=False, show_model=False)\n",
    "\n",
    "# do not forget to switch on again !\n",
    "print('!!!  re-enabling error component ', error_name_ECor)\n",
    "BWfit.enable_error(error_name_ECor)\n",
    "\n",
    "#### fallback option with new fit object\n",
    "#print('!!!  disabling error component ', error_name_ECor)\n",
    "#BWdata.disable_error(error_name_ECor)\n",
    "#_fit = Fit(BWdata, BreitWigner)\n",
    "#_fit.do_fit()\n",
    "#_fit.report(show_data=False, show_model=False)\n",
    "#BWdata.enable_error(error_name_ECor)\n",
    "```\n",
    "\n",
    "Das Ergebnis ist fast identisch zum vorherigen, lediglich die Unsicherheit der Masse ist nun\n",
    "kleiner.\n",
    "Dies war auch so zu erwarten, denn eine korrelierte Änderung aller Energien sollte die Breite\n",
    "oder Höhe der Resonanz nicht beeinflussen.\n",
    "\n",
    "Mit der Methode *enable_error(error_name_ECor)* wird die Fehlerquelle wieder aktiviert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier ausprobieren\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 6. Anpassung an Histogramm-Daten\n",
    "***\n",
    "\n",
    "Im Prinzip lässt sich auch die Anpassung einer Verteilungsdichte an eine Häufigkeitsverteilung\n",
    "als Funktionsanpassung auffassen.\n",
    "Allerdings gibt es einige Besonderheiten, die berücksichtigt werden müssen:\n",
    "\n",
    "- Der dem Wert einer Verteilungsdichte (PDF=Particle Density Function) entsprechende\n",
    "  Funktionswert für ein Bin entspricht dem Integral der PDF über das Bin\n",
    "- Die Unsicherheit eines Bin-Eintrages ergibt sich aus der Poisson-Verteilung, die nur\n",
    "  bei sehr großen Zahlen an Einträgen pro Bin durch eine Gauß-Verteilung angenähert werden kann.\n",
    "   \n",
    "*kafe2* bietet daher eine spezielle Methode zur Anpassung einer Vereilungsdichte an Histogramme,\n",
    "die Klassen *HistContainer* zur Abspeicherung der Histogrammdaten und *HistFit* zur\n",
    "Durchführung der Anpassungen:\n",
    "```\n",
    "from kafe2 import HistContainer, HistFit\n",
    "```\n",
    "\n",
    "Als Kostenfunktion zur Bewertung der Übereinstimmung der angepassten PDF mit den Bin-Einträgen\n",
    "in der Häufigkeitsverteilung wird das Doppelte des negativen Logarithmus der Poisson-Likelihood\n",
    "verwendet, andere Optionen sind konfigurierbar. \n",
    "\n",
    "In diesem einfachen Beispiel verwenden wir die Häufigkeitsverteilung von Gauß-verteilten\n",
    "Zufallszahlen, an die eine Gaußverteilung angepasst wird.\n",
    "```\n",
    "def normal_distribution_pdf(x, mu, sigma):\n",
    "  return np.exp(-0.5 * ((x - mu) / sigma) ** 2) / np.sqrt(2.0 * np.pi * sigma** 2)\n",
    "```\n",
    "\n",
    "Die Daten werden zufällig aus der Standardnormalverteilung erzeugt:\n",
    "```\n",
    "# create a random dataset of 100 random values, \n",
    "#  following a standard normal distribution with mu=0 and sigma=1\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "```\n",
    "\n",
    "Der Datencontainer und das Fit-Objekt werden analog zu den früheren Beispielen erstellt:\n",
    "```\n",
    "# Create a histogram from the dataset by specifying the bin range and the number of bins.\n",
    "# Alternatively the bin edges can be set.\n",
    "histogram = HistContainer(n_bins=10, bin_range=(-5, 5), fill_data=data)\n",
    "\n",
    "# create the Fit object by specifying a density function\n",
    "fit = HistFit(data=histogram, model_density_function=normal_distribution_pdf)\n",
    "```\n",
    "\n",
    "Durchführung der Anpassung und Ausgabe der Ergebnisse unterscheiden sich nicht von der\n",
    "Vorgehensweise bei den früheren Beispielen:\n",
    "```\n",
    "# do the fit\n",
    "fit.do_fit()\n",
    "\n",
    "# Optional: print a report to the terminal\n",
    "fit.report()\n",
    "\n",
    "# Optional: create a plot and show it\n",
    "phist = Plot(fit)\n",
    "phist.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "An dieser Stelle sollten wir noch einmal die Möglichkeiten zur Anpassung der grafischen Ausgabe\n",
    "anschauen.\n",
    "Der Plot-Adapter für Histogramme kennt als *plot_type* die Werte *data*, *model* und\n",
    "*model_density*.\n",
    "Über den Aufruf von `print(phist.get_keywords(<plot_type>))` können die möglichen Parameter zur\n",
    "Einstellung ausgebeben werden.\n",
    "Hier ein Vorschlag für Code zur Anpassung der Grafikausgabe, der vor dem Befehl *phist.plot()*\n",
    "stehen muss:\n",
    "```\n",
    "## reprise: plot customization\n",
    "#    data\n",
    "phist.customize('data', 'label', [\"random Gaussian data\"] ) \n",
    "phist.customize('data', 'marker', ['o'])\n",
    "phist.customize('data', 'markersize', [5])\n",
    "phist.customize('data', 'color', ['blue']) \n",
    "phist.customize('data', 'ecolor', ['blue']) \n",
    "#    model\n",
    "phist.customize('model_density', 'label', [\"Gaussian PDF\"])\n",
    "phist.customize('model_density', 'color', [\"black\"])\n",
    "phist.customize('model', 'label', [\"entries per bin\"])\n",
    "phist.customize('model', 'facecolor', [\"lightgrey\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier ausprobieren \n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7. Likelihood-Anpassungen\n",
    "***\n",
    "\n",
    "Wenn nur wenige Messungen vorhanden sind, ist es nicht möglich, eine sinnvolle\n",
    "Häufigkeitsverteilung zu erhalten, denn eine grobe Einteilung in Bins würde die Messungen\n",
    "verfälschen, während eine zu feine Einteilung zu Bins mit sehr wenigen oder gar null Einträgen\n",
    "führen würde.\n",
    "Das oben schon angewendete Verfahren zur Anpassung einer Verteilungsdichte an eine\n",
    "Häufigkeitsverteilung ist dann nicht anwendbar.\n",
    "In solchen Fällen verwendet man eine direkte Anpassung mit Hilfe des\n",
    "Maximum-Likelihood-Verfahrens and die ungebinnten Daten.\n",
    "Auch dieses Verfahren ist in *kafe2* implementiert.\n",
    "Dazu müssen nur die passenden Klassen importiert werden:\n",
    "```\n",
    "from kafe2.fit import UnbinnedContainer, UnbinnedFit\n",
    "```\n",
    "\n",
    "In diesem Beispiel verwenden wir zur Illustration 160 einzelne Messungen der Lebensdauer von in\n",
    "einem Detektor gestoppten Myonen aus der kosmischen Strahlung.\n",
    "Die Häufigkeitsverteilung ist eine Exponentialverteilung über flachem Untergrund:\n",
    "```\n",
    "def pdf(t, tau=2.2, fbg=0.1, a=1., b=9.75):\n",
    "  \"\"\"\n",
    "  Probability density function for the decay time of a myon. \n",
    "  The pdf is normalized to an integral of one for the interval (a, b).\n",
    "  :param t: decay time\n",
    "  :param fbg: background\n",
    "  :param tau: expected mean of the decay time\n",
    "  :param a: the minimum decay time which can be measured\n",
    "  :param b: the maximum decay time which can be measured\n",
    "  :return: probability for decay time x\n",
    "  \"\"\"\n",
    "  pdf1 = np.exp(-t / tau) / tau / (np.exp(-a / tau) - np.exp(-b / tau))\n",
    "  pdf2 = 1. / (b - a)\n",
    "  return (1 - fbg) * pdf1 + fbg * pdf2\n",
    "```\n",
    "\n",
    "Zu beachten ist, dass die Häufigkeitsverteilung für alle möglichen Parameterwerte auf Eins\n",
    "normiert sein muss!\n",
    "\n",
    "Zur Vorgehensweise bei der Anpassung gibt es nur eine kleine Besonderheit: \n",
    "der Untergrundanteil ist auf Grund der geringen Anzahl an Beobachtungen mit einer großen\n",
    "Unsicherheit behaftet und kann daher bei der Variation im Verlauf des Anpassungsalgorithmus sogar\n",
    "negativ werden.\n",
    "Um diesen \"unphysikalischen\" Bereich des Parameters zu vermeiden, gibt es die Option\n",
    "`fit.limit_parameter(<name>, lower=<min>, upper=<max> )`.\n",
    "\n",
    "Alle weiteren Schritte im folgenden Beispielcode sind bereits bekannt:\n",
    "```\n",
    "data = UnbinnedContainer(dT) # create the kafe data object\n",
    "data.label = 'lifetime measurements'\n",
    "data.axis_labels = ('Myon Life Time ' r'$\\tau$' ' (µs)','Density' )\n",
    "\n",
    "# create the fit object and set the pdf for the fit\n",
    "LLfit = UnbinnedFit(data=data, model_density_function = pdf)\n",
    "\n",
    "# assign latex names for model and parameters for nicer display\n",
    "LLfit.model_label = 'Exponential decay + flat background'\n",
    "LLfit.assign_parameter_latex_names(t='t', tau=r'\\tau', fbg='f', a='a', b='b')\n",
    "LLfit.assign_model_function_latex_expression(\"\\\\frac{{ (1-{fbg}) \\, e^{{-{0}/{tau}}}}}\"\n",
    "    \"{{{tau}(e^{{-{a}/{tau}}}-e^{{-{b}/{tau}}})}} + \\\\frac{{ {fbg} }} {{ {b}-{a} }}\")\n",
    "\n",
    "# Fix the parameters a and b ...\n",
    "a = 1.0\n",
    "b = 11.5\n",
    "LLfit.fix_parameter(\"a\", a)\n",
    "LLfit.fix_parameter(\"b\", b)\n",
    "# ... and limit parameter fbg\n",
    "LLfit.limit_parameter(\"fbg\", lower=0., upper=1.)\n",
    "\n",
    "LLfit.do_fit()  # perform the fit\n",
    "LLfit.report(asymmetric_parameter_errors=True)\n",
    "\n",
    "pLL = Plot(LLfit)  # create a plot object\n",
    "pLL.x_range = [a, b]\n",
    "pLL.plot(fit_info=True, asymmetric_parameter_errors=True)  # plot the data and the fit\n",
    "#pLL.axes[0]['main'].set_xlabel('Life time '+r'$\\tau$'+' (µs)', size='large')  # overwrite the x-axis label\n",
    "\n",
    "cpfLL = ContoursProfiler(LLfit, profile_subtract_min=False)  # Optional: create a contours profile\n",
    "cpfLL.plot_profiles_contours_matrix(parameters=['tau', 'fbg'])  # Optional: plot the contour matrix for tau and fbg\n",
    "\n",
    "plt.show()  # show the plot(s)\n",
    "```\n",
    "\n",
    "Interessant ist die spezielle Form der grafischen Darstellung der Daten, bei der in diesem Fall\n",
    "jeder Messwert durch einen Strich dargestellt wird.\n",
    "Die Dichte der Striche pro Längeneinheit entspricht der Verteilungsdichte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' the data for the myon life time example'''\n",
    "# real data from measurement with a Water Cherenkov detector (\"Kamiokanne\")\n",
    "dT = [7.42, 3.773, 5.968, 4.924,  1.468,  4.664,  1.745,  2.144,  3.836,  3.132,\n",
    "  1.568,  2.352,  2.132,  9.381,  1.484,  1.181,  5.004,  3.06,   4.582,  2.076,\n",
    "  1.88,   1.337,  3.092,  2.265,  1.208,  2.753,  4.457,  3.499,  8.192,  5.101,\n",
    "  1.572,  5.152,  4.181,  3.52,   1.344, 10.29,   1.152,  2.348,  2.228,  2.172,\n",
    "  7.448,  1.108,  4.344,  2.042,  5.088,  1.02,   1.051,  1.987,  1.935,  3.773,\n",
    "  4.092,  1.628,  1.688,  4.502,  4.687,  6.755,  2.56,   1.208,  2.649,  1.012,\n",
    "  1.73,   2.164,  1.728,  4.646,  2.916,  1.101,  2.54,   1.02,   1.176,  4.716,\n",
    "  9.671,  1.692,  9.292, 10.72,   2.164,  2.084,  2.616,  1.584,  5.236,  3.663,\n",
    "  3.624,  1.051,  1.544,  1.496,  1.883,  1.92,   5.968,  5.89,   2.896,  2.76,\n",
    "  1.475,  2.644,  3.6,    5.324,  8.361,  3.052,  7.703,  3.83,   1.444,  1.343,\n",
    "  4.736,  8.7,    6.192,  5.796,  1.4,    3.392,  7.808,  6.344,  1.884,  2.332, \n",
    "  1.76,   4.344,  2.988,  7.44,   5.804,  9.5,    9.904,  3.196,  3.012,  6.056, \n",
    "  6.328,  9.064,  3.068,  9.352,  1.936,  1.08,   1.984,  1.792,  9.384, 10.15,   \n",
    "  4.756,  1.52,   3.912,  1.712, 10.57,   5.304,  2.968,  9.632,  7.116, 1.212,\n",
    "  8.532,  3.000,  4.792,  2.512,  1.352,  2.168,  4.344,  1.316,  1.468, 1.152,\n",
    "  6.024,  3.272,  4.96,  10.16,   2.14,   2.856, 10.01,   1.232, 2.668, 9.176 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood-Anpassung hier ausprobieren\n",
    "# -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 8. Multi-Fits:\n",
    "### simultane Anpassung von Modellfunktionen an verschiedene Datensätze\n",
    "***\n",
    "\n",
    "Sehr oft sind die Modelle zu komplex, um alle Parameter in einer Anpassung an ein einziges Modell\n",
    "zu bestimmen, sondern Modellparameter sind selbst Ergebnisse von Modellanpassungen, oder der\n",
    "selbe Parameter kommt in verschiedenen Messreihen vor.\n",
    "\n",
    "Für solche Fälle bietet *kafe2* die Möglichkeit, mehrere Anpassungen unterschiedlicher Modelle\n",
    "mit gemeinsamen Parametern an verschiedene Datensätze durchzuführen.\n",
    "\n",
    "Dazu muss zusätzlich das Paket *MultiFit* importiert werden:\n",
    "```\n",
    "from kafe2 import MultiFit\n",
    "```\n",
    "\n",
    "Wir betrachten als einfaches Beispiel die Bestimmung eines ohmschen Widerstands bei\n",
    "Zimmertemperatur, der sich bei höherem Stromfluss erwärmt und so seinen Widerstand gemäß seines\n",
    "Temperaturkoeffizienten ändert.\n",
    "Zusätzlich zum Strom durch den Widerstand wird daher noch die Temperatur für jeden vorgegebenen\n",
    "Spannungswert gemessen.\n",
    "Es müssen also Triplets von Messwerten ausgewertet werden.\n",
    "\n",
    "Die Temperaturabhängigkeit wird empirisch durch ein einfaches quadratisches Modell beschreiben:\n",
    "```\n",
    "# empirical model for T(U): a parabola\n",
    "def empirical_T_U_model(U, p2=1.0, p1=1.0, p0=0.0):\n",
    "    # use quadratic model as empirical temperature dependence T(U)\n",
    "    return p2 * U**2 + p1 * U + p0\n",
    "```\n",
    "\n",
    "Der Widerstand als Funktion der Temperatur ist durch den Temperaturkoeffizienten $\\alpha$ gegeben\n",
    "und wird folgendermaßen modelliert:\n",
    "```\n",
    "# model of current-voltage dependence I(U) for a heating resistor\n",
    "def I_U_model(U, R0=1., alph=0.004, p2=1.0, p1=1.0, p0=0.0):\n",
    "    # use quadratic model as empirical temperature dependence T(U)\n",
    "    t_ref = 0.\n",
    "    _delta_t = empirical_T_U_model(U, p2, p1, p0) - t_ref\n",
    "    # plug the temperature into the model\n",
    "    return U / (R0 * (1.0 + _delta_t * alph))\n",
    "```\n",
    "Das Modell für den Widerstand enthält also in diesm Fall das erste Modell für die Abhängigkeit\n",
    "der Temperatur von dem durch die angelegte Spannung bestimmten Strom.\n",
    "\n",
    "Hier die Daten für dieses Beispiel:\n",
    "```\n",
    "# the data \n",
    "U = [ 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5,   \n",
    "      6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0 ] \n",
    "I = [ 0.5,  0.89, 1.41, 1.67, 2.3,  2.59, 2.77, 3.57, 3.94,  4.24, 4.73,\n",
    "      4.87, 5.35, 5.74, 5.77, 6.17, 6.32, 6.83, 6.87, 7.17 ]\n",
    "T = [ 20.35, 20.65, 22.25, 23.65, 26.25, 27.85, 29.85, 34.25, 37.75, 41.95,\n",
    "     44.85, 50.05, 54.25, 60.55, 65.05, 69.95, 76.85, 81.55, 85.45, 94.75 ]\n",
    "sigU, sigI, sigT = 0.2, 0.1, 0.5 # uncertainties\n",
    "```\n",
    "\n",
    "Die Fit-Prozedur unterscheidet sich kaum von der bisher vorgestellten Vorgehensweise. \n",
    "Zunächst werden die Daten-Container und Anpassungen für die beiden Modelle als definiert:\n",
    "```\n",
    "# Step 1: construct the singular data containers and fit objects\n",
    "TU_data = XYContainer(U,T)\n",
    "TU_data.label = 'Temperaturen'\n",
    "TU_data.axis_labels = ['Spannung (V)','Temperatur (°C)']\n",
    "fit_1 = Fit(TU_data, model_function=empirical_T_U_model)\n",
    "fit_1.model_label = 'Parametrisierung'\n",
    "\n",
    "IU_data = XYContainer(U,I)\n",
    "IU_data.label = 'Ströme'\n",
    "IU_data.axis_labels = ['Spannung (V)','Strom (A)']\n",
    "fit_2 = Fit(IU_data, model_function=I_U_model)\n",
    "fit_2.model_label = 'Teperaturabhängiger Leitwert'\n",
    "\n",
    "```\n",
    "\n",
    "Dann werden beide Anpassungen zu einem *MultiFit* zusammengefasst.\n",
    "```\n",
    "# Step 2: construct a MultiFit object\n",
    "multi_fit = MultiFit(fit_list=[fit_1, fit_2], minimizer='iminuit')\n",
    "```\n",
    "Erst jetzt werden die Unsicherheiten - dieses Mal zu den\n",
    "Fit-Objekten, hinzugefügt. Dadurch können auch die in beiden\n",
    "Datensätzen gemeinsamen Unsicherheiten auf der x-Achse berücksichtigt \n",
    "werden. \n",
    "```\n",
    "# Step 3: Add errors (to the fit object in this case)\n",
    "multi_fit.add_error(sigT, 0, axis='y')  # declare errors on T\n",
    "multi_fit.add_error(sigI, 1, axis='y')  # declare errors on I\n",
    "multi_fit.add_error(sigU, 'all', axis='x') # shared error on x axis\n",
    "```\n",
    "\n",
    "Es folgt noch die Definition aussagekräftiger Namen für die Ausgabe:\n",
    "```\n",
    "# (Optional): assign names for models and parameters\n",
    "multi_fit.assign_parameter_latex_names(\n",
    "    U='U', p2='p_2', p1='p_1', p0='p_0', R0='R_0', alph=r'\\alpha_\\mathrm{T}')\n",
    "multi_fit.assign_model_function_expression('{p2}*{U}^2 + {p1}*{U} + {p0}', fit_index=0)\n",
    "multi_fit.assign_model_function_latex_expression(r'{p2}\\,{U}^2 + {p1}\\,{U} + {p0}', fit_index=0)\n",
    "multi_fit.assign_model_function_expression('{U} / ({R0} * (1 + ({p2}*{U}^2 + {p1}*{U} + {p0}) * {alph}))', fit_index=1)\n",
    "multi_fit.assign_model_function_latex_expression(r'\\frac{{{U}}}{{{R0} \\cdot (1 + ({p2}{U}^2 + {p1}{U} + {p0}) \\cdot {alph})}}', fit_index=1)\n",
    "```\n",
    "\n",
    "Der Rest läuft dann genau so wie schon oft gezeigt:\n",
    "```\n",
    "# Step 4: do the fit\n",
    "multi_fit.do_fit()\n",
    "\n",
    "# (Optional): print the results\n",
    "multi_fit.report()\n",
    "\n",
    "# (Optional): plot the results\n",
    "plot = Plot(multi_fit, separate_figures=True)\n",
    "plot.customize('data', 'marker', ['.','.'])\n",
    "plot.customize('data', 'markersize', [6,6])\n",
    "\n",
    "plot.customize('model_error_band', 'label', [(0, r'$\\pm 1\\sigma$'),(1, r'$\\pm 1\\sigma$')])\n",
    "plot.plot()\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Bei der grafischen Darstellung wurde noch mit der schon besprochenen *customize*-Methode ein\n",
    "angepasster Eintrag in der Legende für das Unsicherheitsband gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenen Code hier eingeben\n",
    "# -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}